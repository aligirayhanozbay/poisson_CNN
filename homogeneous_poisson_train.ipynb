{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import Homogeneous_Poisson_NN\n",
    "from Homogeneous_Poisson_NN import Homogeneous_Poisson_NN_2#,Homogeneous_Poisson_NN\n",
    "from Lp_integral_norm import Lp_integral_norm\n",
    "from generate_cholesky_soln import generate_dataset\n",
    "from generate_analytical_soln import generate_analytical_solution_homogeneous_bc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Homogeneous_Poisson_NN(data_format = 'channels_first')\n",
    "mod(tf.random.uniform((1,1,74,83), dtype = tf.keras.backend.floatx()))\n",
    "mod.load_weights('Homogeneous_Poisson_NN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generator(n_batches = 60, dx = 0.1*(np.random.rand() + 0.01), nx = 64, ny = 64):\n",
    "    #dx = \n",
    "#     nx = np.random.randint(64,128)\n",
    "#     ny = np.random.randint(64,128)\n",
    "#     if np.random.rand() > 0.5:\n",
    "#         nx = 64\n",
    "#     else:\n",
    "#         nx = 64\n",
    "        \n",
    "#     if np.random.rand() > 0.5:\n",
    "#         ny = 64\n",
    "#     else:\n",
    "#         ny = 64\n",
    "    batch_size = 125\n",
    "    while True:\n",
    "        if np.random.rand() > 0.5:\n",
    "            yield tuple(reversed(generate_analytical_solution_homogeneous_bc(output_shape=(ny,nx), nmodes=(32,32), max_random_magnitude=1.0, domain = [(nx-1)*dx, (ny-1)*dx], n_random=batch_size, expanded_dims = True)))\n",
    "        else:\n",
    "            yield tuple(reversed(generate_dataset(batch_size, [nx,ny], dx, {'top':np.zeros(nx),'bottom':np.zeros(nx),'left':np.zeros(ny),'right':np.zeros(ny)})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Homogeneous_Poisson_NN_2(data_format = 'channels_first', mse_component_weight = 1e+1)\n",
    "mod((tf.random.uniform((10,1,74,83), dtype = tf.keras.backend.floatx()), tf.random.uniform((10,1), dtype = tf.keras.backend.floatx())))\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "#mod.load_weights('Homogeneous_Poisson_NN_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNOTES:\\n-Mixing 'analytical dataset' and Cholesky seems to result in not-so-good behaviour\\n-Learning rate should be super small\\n\\n---these parameters led to decent results on the variable dx 64x64 case: (results saved in Homogeneous_Poisson_NN_2.h5)\\ndataset:\\nbatch size 125, Fourier data excluded\\ntraining:\\ncb = [tf.keras.callbacks.ModelCheckpoint('Homogeneous_Poisson_NN_2.h5', monitor='loss', verbose=1, save_best_only=True, save_weights_only=True), tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', min_lr = 1e-15)]\\nmod.compile(loss = mod.integral_loss, optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5), metrics = ['mse', 'mae'])\\nmod.run_eagerly = True\\nmod.fit_generator(generator=dataset_generator_2(), steps_per_epoch=600, epochs=5000, validation_data=dataset_generator_2(), validation_steps=3, callbacks=cb)\\n\\nWhen trained on ONLY interpolation dataset, the results for the analytical one are max 10% off pointwise!\\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataset_generator_2(n_batches = 60, dx = 0.1*(np.random.rand() + 0.01), nx = 64, ny = 64):\n",
    "    \n",
    "#     nx = np.random.randint(64,128)\n",
    "#     ny = np.random.randint(64,128)\n",
    "#     if np.random.rand() > 0.5:\n",
    "#         nx = 64\n",
    "#     else:\n",
    "#         nx = 64\n",
    "        \n",
    "#     if np.random.rand() > 0.5:\n",
    "#         ny = 64\n",
    "#     else:\n",
    "#         ny = 64\n",
    "    batch_size = 125\n",
    "    while True:\n",
    "        dx = 0.1*(np.random.rand() + 0.01)\n",
    "        if np.random.rand() < -1:\n",
    "            soln, rhs = generate_analytical_solution_homogeneous_bc(output_shape=(ny,nx), nmodes=(32,32), max_random_magnitude=1.0, domain = [(nx-1)*dx, (ny-1)*dx], n_random=batch_size, expanded_dims = True)\n",
    "            yield ((rhs, dx * tf.ones((batch_size,1), dtype = tf.keras.backend.floatx())), soln)\n",
    "        else:\n",
    "            soln, rhs = generate_dataset(batch_size, [nx,ny], dx, {'top':np.zeros(nx),'bottom':np.zeros(nx),'left':np.zeros(ny),'right':np.zeros(ny)})\n",
    "            yield ((rhs, dx * tf.ones((batch_size,1), dtype = tf.keras.backend.floatx())), soln)\n",
    "def dataset_generator_2_rbg():\n",
    "    batch_size = 125\n",
    "    while True:\n",
    "        nx = np.random.randint(64,128)\n",
    "        ny = np.random.randint(64,128)\n",
    "#         if np.random.rand() > 0.5:\n",
    "#             nx = 64\n",
    "#         else:\n",
    "#             nx = 64\n",
    "\n",
    "#         if np.random.rand() > 0.5:\n",
    "#             ny = 64\n",
    "#         else:\n",
    "#             ny = 64\n",
    "        dx = 0.1*(np.random.rand() + 0.01)\n",
    "        if np.random.rand() < -1:\n",
    "            soln, rhs = generate_analytical_solution_homogeneous_bc(output_shape=(ny,nx), nmodes=(32,32), max_random_magnitude=1.0, domain = [(nx-1)*dx, (ny-1)*dx], n_random=batch_size, expanded_dims = True)\n",
    "            yield ((rhs, dx * tf.ones((batch_size,1), dtype = tf.keras.backend.floatx())), soln)\n",
    "        else:\n",
    "            soln, rhs = generate_dataset(batch_size, [nx,ny], dx, {'top':np.zeros(nx),'bottom':np.zeros(nx),'left':np.zeros(ny),'right':np.zeros(ny)})\n",
    "            yield ((rhs, dx * tf.ones((batch_size,1), dtype = tf.keras.backend.floatx())), soln)\n",
    "\n",
    "'''\n",
    "NOTES:\n",
    "-Mixing 'analytical dataset' and Cholesky seems to result in not-so-good behaviour\n",
    "-Learning rate should be super small\n",
    "\n",
    "---these parameters led to decent results on the variable dx 64x64 case: (results saved in Homogeneous_Poisson_NN_2.h5)\n",
    "dataset:\n",
    "batch size 125, Fourier data excluded\n",
    "training:\n",
    "cb = [tf.keras.callbacks.ModelCheckpoint('Homogeneous_Poisson_NN_2.h5', monitor='loss', verbose=1, save_best_only=True, save_weights_only=True), tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', min_lr = 1e-15)]\n",
    "mod.compile(loss = mod.integral_loss, optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5), metrics = ['mse', 'mae'])\n",
    "mod.run_eagerly = True\n",
    "mod.fit_generator(generator=dataset_generator_2(), steps_per_epoch=600, epochs=5000, validation_data=dataset_generator_2(), validation_steps=3, callbacks=cb)\n",
    "\n",
    "When trained on ONLY interpolation dataset, the results for the analytical one are max 10% off pointwise!\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "599/600 [============================>.] - ETA: 4s - loss: 0.8258 - mse: 0.0206 - mae: 0.0658\n",
      "Epoch 00001: loss improved from inf to 0.82460, saving model to Homogeneous_Poisson_NN_3.h5\n",
      "600/600 [==============================] - 2935s 5s/step - loss: 0.8246 - mse: 0.0206 - mae: 0.0657 - val_loss: 0.6236 - val_mse: 0.0087 - val_mae: 0.0545\n",
      "Epoch 2/5000\n",
      "284/600 [=============>................] - ETA: 24:14 - loss: 0.6172 - mse: 0.0133 - mae: 0.0518"
     ]
    }
   ],
   "source": [
    "cb = [tf.keras.callbacks.ModelCheckpoint('Homogeneous_Poisson_NN_3.h5', monitor='loss', verbose=1, save_best_only=True, save_weights_only=True), tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', min_lr = 1e-15)]\n",
    "mod.compile(loss = mod.integral_loss, optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3), metrics = ['mse', 'mae'])\n",
    "mod.run_eagerly = True\n",
    "mod.fit_generator(generator=dataset_generator_2_rbg(), steps_per_epoch=600, epochs=5000, validation_data=dataset_generator_2_rbg(), validation_steps=3, callbacks=cb)\n",
    "#maybe incorporate delta x and domain size information? via [dx, dy, Lx, Ly] -> dense layers -> einsum into conv filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.save_weights('Homogeneous_Poisson_NN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 0.1*(np.random.rand() + 0.01)#0.04016651#0.05#\n",
    "nx = 64#np.random.randint(64,128)\n",
    "ny = 64#np.random.randint(64,128)\n",
    "batch_size = 100\n",
    "soln, rhs = generate_analytical_solution_homogeneous_bc(output_shape=(ny,nx), nmodes=(32,32), max_random_magnitude=1.0, domain = [(nx-1)*dx, (ny-1)*dx], n_random=batch_size, expanded_dims= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034681940925285794"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64)\n",
      "(64, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = np.meshgrid(np.linspace(0, soln.shape[-2]*dx, soln.shape[-2]), np.linspace(0, soln.shape[-1]*dx, soln.shape[-1]), indexing = 'ij')\n",
    "#p_r = np.random.randint(0,soln.shape[0])\n",
    "z = soln[p_r,0,...]\n",
    "#z = rhs[p_r,...]\n",
    "print(z.shape)\n",
    "print(x.shape)\n",
    "z = mod((rhs, dx * tf.ones((batch_size,1), dtype = tf.keras.backend.floatx())))[p_r,0,...]\n",
    "#z = mod((rhs, dx * tf.ones((batch_size,1), dtype = tf.keras.backend.floatx())))[p_r,0,...] - soln[p_r,0,...]\n",
    "z = tf.divide(mod((rhs, dx * tf.ones((batch_size,1), dtype = tf.keras.backend.floatx())))[p_r,0,...] - soln[p_r,0,...], soln[p_r,0,...])\n",
    "z_min, z_max = -np.abs(z).max(), np.abs(z).max()\n",
    "fig, ax = plt.subplots()\n",
    "c = ax.pcolormesh(x, y, z, cmap='RdBu', vmin=z_min, vmax=z_max)\n",
    "ax.set_title('result')\n",
    "ax.axis([x.min(), x.max(), y.min(), y.max()])\n",
    "fig.colorbar(c, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conv_laplacian_loss import conv_laplacian_loss\n",
    "cll = conv_laplacian_loss((ny,nx), dx)\n",
    "#cll(tf.expand_dims(rhs, axis = 1), tf.expand_dims(soln, axis = 1))\n",
    "cll(rhs,soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.compile(loss = lf, optimizer = tf.keras.optimizers.Adam(learning_rate = 5e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008789778496342436"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 1, 128, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=72203, shape=(), dtype=float64, numpy=2.72116787741319>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = (tf.random.uniform((100,1,67,96), dtype = tf.float64), 0.05 * tf.ones((100,1), dtype = tf.float64))\n",
    "s = (tf.random.uniform((100,1,67,96), dtype = tf.float64), 0.05 * tf.ones((100,1), dtype = tf.float64))\n",
    "Lp_integral_norm_batch(r,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "---data---\n",
      "(1, 1, 100, 100)\n",
      "---index combinations---\n",
      "(20, 20, 4, 2)\n",
      "---interp_pts---\n",
      "(20, 20, 4, 1)\n",
      "---quadweights---\n",
      "tf.Tensor(\n",
      "[[7.75633119e-05 1.78788469e-04 2.75976477e-04 3.66709280e-04\n",
      "  4.48849465e-04 5.20469832e-04 5.79891154e-04 6.25720471e-04\n",
      "  6.56883512e-04 6.72649813e-04 6.72649813e-04 6.56883512e-04\n",
      "  6.25720471e-04 5.79891154e-04 5.20469832e-04 4.48849465e-04\n",
      "  3.66709280e-04 2.75976477e-04 1.78788469e-04 7.75633119e-05]\n",
      " [1.78788469e-04 4.12119025e-04 6.36143693e-04 8.45288694e-04\n",
      "  1.03462715e-03 1.19971675e-03 1.33668675e-03 1.44232630e-03\n",
      "  1.51415913e-03 1.55050148e-03 1.55050148e-03 1.51415913e-03\n",
      "  1.44232630e-03 1.33668675e-03 1.19971675e-03 1.03462715e-03\n",
      "  8.45288694e-04 6.36143693e-04 4.12119025e-04 1.78788469e-04]\n",
      " [2.75976477e-04 6.36143693e-04 9.81946411e-04 1.30478099e-03\n",
      "  1.59704235e-03 1.85187335e-03 2.06329918e-03 2.22636356e-03\n",
      "  2.33724415e-03 2.39334192e-03 2.39334192e-03 2.33724415e-03\n",
      "  2.22636356e-03 2.06329918e-03 1.85187335e-03 1.59704235e-03\n",
      "  1.30478099e-03 9.81946411e-04 6.36143693e-04 2.75976477e-04]\n",
      " [3.66709280e-04 8.45288694e-04 1.30478099e-03 1.73375392e-03\n",
      "  2.12210206e-03 2.46071387e-03 2.74165018e-03 2.95832524e-03\n",
      "  3.10566006e-03 3.18020109e-03 3.18020109e-03 3.10566006e-03\n",
      "  2.95832524e-03 2.74165018e-03 2.46071387e-03 2.12210206e-03\n",
      "  1.73375392e-03 1.30478099e-03 8.45288694e-04 3.66709280e-04]\n",
      " [4.48849465e-04 1.03462715e-03 1.59704235e-03 2.12210206e-03\n",
      "  2.59743733e-03 3.01189570e-03 3.35575967e-03 3.62096836e-03\n",
      "  3.80130510e-03 3.89254276e-03 3.89254276e-03 3.80130510e-03\n",
      "  3.62096836e-03 3.35575967e-03 3.01189570e-03 2.59743733e-03\n",
      "  2.12210206e-03 1.59704235e-03 1.03462715e-03 4.48849465e-04]\n",
      " [5.20469832e-04 1.19971675e-03 1.85187335e-03 2.46071387e-03\n",
      "  3.01189570e-03 3.49248685e-03 3.89121925e-03 4.19874578e-03\n",
      "  4.40785783e-03 4.51365377e-03 4.51365377e-03 4.40785783e-03\n",
      "  4.19874578e-03 3.89121925e-03 3.49248685e-03 3.01189570e-03\n",
      "  2.46071387e-03 1.85187335e-03 1.19971675e-03 5.20469832e-04]\n",
      " [5.79891154e-04 1.33668675e-03 2.06329918e-03 2.74165018e-03\n",
      "  3.35575967e-03 3.89121925e-03 4.33547437e-03 4.67811079e-03\n",
      "  4.91109687e-03 5.02897139e-03 5.02897139e-03 4.91109687e-03\n",
      "  4.67811079e-03 4.33547437e-03 3.89121925e-03 3.35575967e-03\n",
      "  2.74165018e-03 2.06329918e-03 1.33668675e-03 5.79891154e-04]\n",
      " [6.25720471e-04 1.44232630e-03 2.22636356e-03 2.95832524e-03\n",
      "  3.62096836e-03 4.19874578e-03 4.67811079e-03 5.04782607e-03\n",
      "  5.29922525e-03 5.42641550e-03 5.42641550e-03 5.29922525e-03\n",
      "  5.04782607e-03 4.67811079e-03 4.19874578e-03 3.62096836e-03\n",
      "  2.95832524e-03 2.22636356e-03 1.44232630e-03 6.25720471e-04]\n",
      " [6.56883512e-04 1.51415913e-03 2.33724415e-03 3.10566006e-03\n",
      "  3.80130510e-03 4.40785783e-03 4.91109687e-03 5.29922525e-03\n",
      "  5.56314497e-03 5.69666974e-03 5.69666974e-03 5.56314497e-03\n",
      "  5.29922525e-03 4.91109687e-03 4.40785783e-03 3.80130510e-03\n",
      "  3.10566006e-03 2.33724415e-03 1.51415913e-03 6.56883512e-04]\n",
      " [6.72649813e-04 1.55050148e-03 2.39334192e-03 3.18020109e-03\n",
      "  3.89254276e-03 4.51365377e-03 5.02897139e-03 5.42641550e-03\n",
      "  5.69666974e-03 5.83339932e-03 5.83339932e-03 5.69666974e-03\n",
      "  5.42641550e-03 5.02897139e-03 4.51365377e-03 3.89254276e-03\n",
      "  3.18020109e-03 2.39334192e-03 1.55050148e-03 6.72649813e-04]\n",
      " [6.72649813e-04 1.55050148e-03 2.39334192e-03 3.18020109e-03\n",
      "  3.89254276e-03 4.51365377e-03 5.02897139e-03 5.42641550e-03\n",
      "  5.69666974e-03 5.83339932e-03 5.83339932e-03 5.69666974e-03\n",
      "  5.42641550e-03 5.02897139e-03 4.51365377e-03 3.89254276e-03\n",
      "  3.18020109e-03 2.39334192e-03 1.55050148e-03 6.72649813e-04]\n",
      " [6.56883512e-04 1.51415913e-03 2.33724415e-03 3.10566006e-03\n",
      "  3.80130510e-03 4.40785783e-03 4.91109687e-03 5.29922525e-03\n",
      "  5.56314497e-03 5.69666974e-03 5.69666974e-03 5.56314497e-03\n",
      "  5.29922525e-03 4.91109687e-03 4.40785783e-03 3.80130510e-03\n",
      "  3.10566006e-03 2.33724415e-03 1.51415913e-03 6.56883512e-04]\n",
      " [6.25720471e-04 1.44232630e-03 2.22636356e-03 2.95832524e-03\n",
      "  3.62096836e-03 4.19874578e-03 4.67811079e-03 5.04782607e-03\n",
      "  5.29922525e-03 5.42641550e-03 5.42641550e-03 5.29922525e-03\n",
      "  5.04782607e-03 4.67811079e-03 4.19874578e-03 3.62096836e-03\n",
      "  2.95832524e-03 2.22636356e-03 1.44232630e-03 6.25720471e-04]\n",
      " [5.79891154e-04 1.33668675e-03 2.06329918e-03 2.74165018e-03\n",
      "  3.35575967e-03 3.89121925e-03 4.33547437e-03 4.67811079e-03\n",
      "  4.91109687e-03 5.02897139e-03 5.02897139e-03 4.91109687e-03\n",
      "  4.67811079e-03 4.33547437e-03 3.89121925e-03 3.35575967e-03\n",
      "  2.74165018e-03 2.06329918e-03 1.33668675e-03 5.79891154e-04]\n",
      " [5.20469832e-04 1.19971675e-03 1.85187335e-03 2.46071387e-03\n",
      "  3.01189570e-03 3.49248685e-03 3.89121925e-03 4.19874578e-03\n",
      "  4.40785783e-03 4.51365377e-03 4.51365377e-03 4.40785783e-03\n",
      "  4.19874578e-03 3.89121925e-03 3.49248685e-03 3.01189570e-03\n",
      "  2.46071387e-03 1.85187335e-03 1.19971675e-03 5.20469832e-04]\n",
      " [4.48849465e-04 1.03462715e-03 1.59704235e-03 2.12210206e-03\n",
      "  2.59743733e-03 3.01189570e-03 3.35575967e-03 3.62096836e-03\n",
      "  3.80130510e-03 3.89254276e-03 3.89254276e-03 3.80130510e-03\n",
      "  3.62096836e-03 3.35575967e-03 3.01189570e-03 2.59743733e-03\n",
      "  2.12210206e-03 1.59704235e-03 1.03462715e-03 4.48849465e-04]\n",
      " [3.66709280e-04 8.45288694e-04 1.30478099e-03 1.73375392e-03\n",
      "  2.12210206e-03 2.46071387e-03 2.74165018e-03 2.95832524e-03\n",
      "  3.10566006e-03 3.18020109e-03 3.18020109e-03 3.10566006e-03\n",
      "  2.95832524e-03 2.74165018e-03 2.46071387e-03 2.12210206e-03\n",
      "  1.73375392e-03 1.30478099e-03 8.45288694e-04 3.66709280e-04]\n",
      " [2.75976477e-04 6.36143693e-04 9.81946411e-04 1.30478099e-03\n",
      "  1.59704235e-03 1.85187335e-03 2.06329918e-03 2.22636356e-03\n",
      "  2.33724415e-03 2.39334192e-03 2.39334192e-03 2.33724415e-03\n",
      "  2.22636356e-03 2.06329918e-03 1.85187335e-03 1.59704235e-03\n",
      "  1.30478099e-03 9.81946411e-04 6.36143693e-04 2.75976477e-04]\n",
      " [1.78788469e-04 4.12119025e-04 6.36143693e-04 8.45288694e-04\n",
      "  1.03462715e-03 1.19971675e-03 1.33668675e-03 1.44232630e-03\n",
      "  1.51415913e-03 1.55050148e-03 1.55050148e-03 1.51415913e-03\n",
      "  1.44232630e-03 1.33668675e-03 1.19971675e-03 1.03462715e-03\n",
      "  8.45288694e-04 6.36143693e-04 4.12119025e-04 1.78788469e-04]\n",
      " [7.75633119e-05 1.78788469e-04 2.75976477e-04 3.66709280e-04\n",
      "  4.48849465e-04 5.20469832e-04 5.79891154e-04 6.25720471e-04\n",
      "  6.56883512e-04 6.72649813e-04 6.72649813e-04 6.56883512e-04\n",
      "  6.25720471e-04 5.79891154e-04 5.20469832e-04 4.48849465e-04\n",
      "  3.66709280e-04 2.75976477e-04 1.78788469e-04 7.75633119e-05]], shape=(20, 20), dtype=float64)\n",
      "---b---\n",
      "(20, 20, 4)\n",
      "---values_at_quad_pts---\n",
      "(20, 20, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=946104, shape=(), dtype=float64, numpy=0.38204612888195494>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(Homogeneous_Poisson_NN)\n",
    "mod = Homogeneous_Poisson_NN.Homogeneous_Poisson_NN_2(data_format = 'channels_first', Lp_norm_power=2)\n",
    "nx1 = 100\n",
    "nx2 = 100\n",
    "dx = 0.01\n",
    "Lx1 = 1.0\n",
    "Lx2 = 1.0\n",
    "batch_size = 1\n",
    "mod((tf.random.uniform((10,1,74,83), dtype = tf.keras.backend.floatx()), dx*tf.ones((batch_size,1), dtype = tf.keras.backend.floatx())))\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "x = np.array(np.meshgrid(np.linspace(0, Lx1, nx1),np.linspace(0, Lx2, nx2),indexing = 'xy'), dtype = np.float64).transpose((1,2,0))\n",
    "y = np.sin(x[:,:,0] - x[:,:,1])\n",
    "mod.integral_loss_2(y, tf.zeros((batch_size,1,nx1,nx2), dtype = tf.float64)) #ttf.ones((batch_size,1,nx1,nx2), dtype = tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01761401 0.04060143 0.06267205 0.08327674 0.10193012 0.11819453\n",
      " 0.13168864 0.14209611 0.14917299 0.15275339 0.15275339 0.14917299\n",
      " 0.14209611 0.13168864 0.11819453 0.10193012 0.08327674 0.06267205\n",
      " 0.04060143 0.01761401]\n",
      "[0.5 0.5]\n",
      "---data---\n",
      "(100, 100, 1, 1)\n",
      "---index combinations---\n",
      "(20, 20, 4, 2)\n",
      "---quadweights---\n",
      "tf.Tensor(\n",
      "[[7.75633119e-05 1.78788469e-04 2.75976477e-04 3.66709280e-04\n",
      "  4.48849465e-04 5.20469832e-04 5.79891154e-04 6.25720471e-04\n",
      "  6.56883512e-04 6.72649813e-04 6.72649813e-04 6.56883512e-04\n",
      "  6.25720471e-04 5.79891154e-04 5.20469832e-04 4.48849465e-04\n",
      "  3.66709280e-04 2.75976477e-04 1.78788469e-04 7.75633119e-05]\n",
      " [1.78788469e-04 4.12119025e-04 6.36143693e-04 8.45288694e-04\n",
      "  1.03462715e-03 1.19971675e-03 1.33668675e-03 1.44232630e-03\n",
      "  1.51415913e-03 1.55050148e-03 1.55050148e-03 1.51415913e-03\n",
      "  1.44232630e-03 1.33668675e-03 1.19971675e-03 1.03462715e-03\n",
      "  8.45288694e-04 6.36143693e-04 4.12119025e-04 1.78788469e-04]\n",
      " [2.75976477e-04 6.36143693e-04 9.81946411e-04 1.30478099e-03\n",
      "  1.59704235e-03 1.85187335e-03 2.06329918e-03 2.22636356e-03\n",
      "  2.33724415e-03 2.39334192e-03 2.39334192e-03 2.33724415e-03\n",
      "  2.22636356e-03 2.06329918e-03 1.85187335e-03 1.59704235e-03\n",
      "  1.30478099e-03 9.81946411e-04 6.36143693e-04 2.75976477e-04]\n",
      " [3.66709280e-04 8.45288694e-04 1.30478099e-03 1.73375392e-03\n",
      "  2.12210206e-03 2.46071387e-03 2.74165018e-03 2.95832524e-03\n",
      "  3.10566006e-03 3.18020109e-03 3.18020109e-03 3.10566006e-03\n",
      "  2.95832524e-03 2.74165018e-03 2.46071387e-03 2.12210206e-03\n",
      "  1.73375392e-03 1.30478099e-03 8.45288694e-04 3.66709280e-04]\n",
      " [4.48849465e-04 1.03462715e-03 1.59704235e-03 2.12210206e-03\n",
      "  2.59743733e-03 3.01189570e-03 3.35575967e-03 3.62096836e-03\n",
      "  3.80130510e-03 3.89254276e-03 3.89254276e-03 3.80130510e-03\n",
      "  3.62096836e-03 3.35575967e-03 3.01189570e-03 2.59743733e-03\n",
      "  2.12210206e-03 1.59704235e-03 1.03462715e-03 4.48849465e-04]\n",
      " [5.20469832e-04 1.19971675e-03 1.85187335e-03 2.46071387e-03\n",
      "  3.01189570e-03 3.49248685e-03 3.89121925e-03 4.19874578e-03\n",
      "  4.40785783e-03 4.51365377e-03 4.51365377e-03 4.40785783e-03\n",
      "  4.19874578e-03 3.89121925e-03 3.49248685e-03 3.01189570e-03\n",
      "  2.46071387e-03 1.85187335e-03 1.19971675e-03 5.20469832e-04]\n",
      " [5.79891154e-04 1.33668675e-03 2.06329918e-03 2.74165018e-03\n",
      "  3.35575967e-03 3.89121925e-03 4.33547437e-03 4.67811079e-03\n",
      "  4.91109687e-03 5.02897139e-03 5.02897139e-03 4.91109687e-03\n",
      "  4.67811079e-03 4.33547437e-03 3.89121925e-03 3.35575967e-03\n",
      "  2.74165018e-03 2.06329918e-03 1.33668675e-03 5.79891154e-04]\n",
      " [6.25720471e-04 1.44232630e-03 2.22636356e-03 2.95832524e-03\n",
      "  3.62096836e-03 4.19874578e-03 4.67811079e-03 5.04782607e-03\n",
      "  5.29922525e-03 5.42641550e-03 5.42641550e-03 5.29922525e-03\n",
      "  5.04782607e-03 4.67811079e-03 4.19874578e-03 3.62096836e-03\n",
      "  2.95832524e-03 2.22636356e-03 1.44232630e-03 6.25720471e-04]\n",
      " [6.56883512e-04 1.51415913e-03 2.33724415e-03 3.10566006e-03\n",
      "  3.80130510e-03 4.40785783e-03 4.91109687e-03 5.29922525e-03\n",
      "  5.56314497e-03 5.69666974e-03 5.69666974e-03 5.56314497e-03\n",
      "  5.29922525e-03 4.91109687e-03 4.40785783e-03 3.80130510e-03\n",
      "  3.10566006e-03 2.33724415e-03 1.51415913e-03 6.56883512e-04]\n",
      " [6.72649813e-04 1.55050148e-03 2.39334192e-03 3.18020109e-03\n",
      "  3.89254276e-03 4.51365377e-03 5.02897139e-03 5.42641550e-03\n",
      "  5.69666974e-03 5.83339932e-03 5.83339932e-03 5.69666974e-03\n",
      "  5.42641550e-03 5.02897139e-03 4.51365377e-03 3.89254276e-03\n",
      "  3.18020109e-03 2.39334192e-03 1.55050148e-03 6.72649813e-04]\n",
      " [6.72649813e-04 1.55050148e-03 2.39334192e-03 3.18020109e-03\n",
      "  3.89254276e-03 4.51365377e-03 5.02897139e-03 5.42641550e-03\n",
      "  5.69666974e-03 5.83339932e-03 5.83339932e-03 5.69666974e-03\n",
      "  5.42641550e-03 5.02897139e-03 4.51365377e-03 3.89254276e-03\n",
      "  3.18020109e-03 2.39334192e-03 1.55050148e-03 6.72649813e-04]\n",
      " [6.56883512e-04 1.51415913e-03 2.33724415e-03 3.10566006e-03\n",
      "  3.80130510e-03 4.40785783e-03 4.91109687e-03 5.29922525e-03\n",
      "  5.56314497e-03 5.69666974e-03 5.69666974e-03 5.56314497e-03\n",
      "  5.29922525e-03 4.91109687e-03 4.40785783e-03 3.80130510e-03\n",
      "  3.10566006e-03 2.33724415e-03 1.51415913e-03 6.56883512e-04]\n",
      " [6.25720471e-04 1.44232630e-03 2.22636356e-03 2.95832524e-03\n",
      "  3.62096836e-03 4.19874578e-03 4.67811079e-03 5.04782607e-03\n",
      "  5.29922525e-03 5.42641550e-03 5.42641550e-03 5.29922525e-03\n",
      "  5.04782607e-03 4.67811079e-03 4.19874578e-03 3.62096836e-03\n",
      "  2.95832524e-03 2.22636356e-03 1.44232630e-03 6.25720471e-04]\n",
      " [5.79891154e-04 1.33668675e-03 2.06329918e-03 2.74165018e-03\n",
      "  3.35575967e-03 3.89121925e-03 4.33547437e-03 4.67811079e-03\n",
      "  4.91109687e-03 5.02897139e-03 5.02897139e-03 4.91109687e-03\n",
      "  4.67811079e-03 4.33547437e-03 3.89121925e-03 3.35575967e-03\n",
      "  2.74165018e-03 2.06329918e-03 1.33668675e-03 5.79891154e-04]\n",
      " [5.20469832e-04 1.19971675e-03 1.85187335e-03 2.46071387e-03\n",
      "  3.01189570e-03 3.49248685e-03 3.89121925e-03 4.19874578e-03\n",
      "  4.40785783e-03 4.51365377e-03 4.51365377e-03 4.40785783e-03\n",
      "  4.19874578e-03 3.89121925e-03 3.49248685e-03 3.01189570e-03\n",
      "  2.46071387e-03 1.85187335e-03 1.19971675e-03 5.20469832e-04]\n",
      " [4.48849465e-04 1.03462715e-03 1.59704235e-03 2.12210206e-03\n",
      "  2.59743733e-03 3.01189570e-03 3.35575967e-03 3.62096836e-03\n",
      "  3.80130510e-03 3.89254276e-03 3.89254276e-03 3.80130510e-03\n",
      "  3.62096836e-03 3.35575967e-03 3.01189570e-03 2.59743733e-03\n",
      "  2.12210206e-03 1.59704235e-03 1.03462715e-03 4.48849465e-04]\n",
      " [3.66709280e-04 8.45288694e-04 1.30478099e-03 1.73375392e-03\n",
      "  2.12210206e-03 2.46071387e-03 2.74165018e-03 2.95832524e-03\n",
      "  3.10566006e-03 3.18020109e-03 3.18020109e-03 3.10566006e-03\n",
      "  2.95832524e-03 2.74165018e-03 2.46071387e-03 2.12210206e-03\n",
      "  1.73375392e-03 1.30478099e-03 8.45288694e-04 3.66709280e-04]\n",
      " [2.75976477e-04 6.36143693e-04 9.81946411e-04 1.30478099e-03\n",
      "  1.59704235e-03 1.85187335e-03 2.06329918e-03 2.22636356e-03\n",
      "  2.33724415e-03 2.39334192e-03 2.39334192e-03 2.33724415e-03\n",
      "  2.22636356e-03 2.06329918e-03 1.85187335e-03 1.59704235e-03\n",
      "  1.30478099e-03 9.81946411e-04 6.36143693e-04 2.75976477e-04]\n",
      " [1.78788469e-04 4.12119025e-04 6.36143693e-04 8.45288694e-04\n",
      "  1.03462715e-03 1.19971675e-03 1.33668675e-03 1.44232630e-03\n",
      "  1.51415913e-03 1.55050148e-03 1.55050148e-03 1.51415913e-03\n",
      "  1.44232630e-03 1.33668675e-03 1.19971675e-03 1.03462715e-03\n",
      "  8.45288694e-04 6.36143693e-04 4.12119025e-04 1.78788469e-04]\n",
      " [7.75633119e-05 1.78788469e-04 2.75976477e-04 3.66709280e-04\n",
      "  4.48849465e-04 5.20469832e-04 5.79891154e-04 6.25720471e-04\n",
      "  6.56883512e-04 6.72649813e-04 6.72649813e-04 6.56883512e-04\n",
      "  6.25720471e-04 5.79891154e-04 5.20469832e-04 4.48849465e-04\n",
      "  3.66709280e-04 2.75976477e-04 1.78788469e-04 7.75633119e-05]], shape=(20, 20), dtype=float64)\n",
      "---b---\n",
      "(20, 20, 4)\n",
      "---interp_pts---\n",
      "(20, 20, 4)\n",
      "---values_at_quad_pts---\n",
      "(20, 20, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=929183, shape=(), dtype=float64, numpy=0.3820461288819584>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf = Lp_integral_norm([nx1,nx2], [0,Lx1,0,Lx2], n_quadpts=20, p = 2.0)\n",
    "lf(y, tf.zeros((1,1,nx1,nx2), dtype = tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<tf.Tensor: id=3546663, shape=(200, 1, 120, 69), dtype=float64, numpy=\n",
      "array([[[[ 0.84045724,  0.81368467,  0.78558265, ..., -0.13076901,\n",
      "          -0.14837462, -0.16357844],\n",
      "         [ 0.8085973 ,  0.78179162,  0.7534852 , ..., -0.10406169,\n",
      "          -0.11942291, -0.1326621 ],\n",
      "         [ 0.77454948,  0.74760936,  0.71896215, ..., -0.07340205,\n",
      "          -0.08610965, -0.09702934],\n",
      "         ...,\n",
      "         [ 0.28107054,  0.27042851,  0.26098092, ..., -0.10538607,\n",
      "          -0.15177625, -0.18997541],\n",
      "         [ 0.28166855,  0.27174322,  0.2632169 , ..., -0.09809176,\n",
      "          -0.14420833, -0.18208804],\n",
      "         [ 0.28370473,  0.27434141,  0.26655056, ..., -0.09171168,\n",
      "          -0.1375604 , -0.17513601]]],\n",
      "\n",
      "\n",
      "       [[[ 0.60275823,  0.6109267 ,  0.62123793, ...,  0.25581462,\n",
      "           0.25737733,  0.25815948],\n",
      "         [ 0.60529005,  0.61218977,  0.62107793, ...,  0.25583302,\n",
      "           0.25900226,  0.26121037],\n",
      "         [ 0.60771822,  0.61328003,  0.6206704 , ...,  0.25555844,\n",
      "           0.2604928 ,  0.26426733],\n",
      "         ...,\n",
      "         [-0.00231488, -0.04582352, -0.09909789, ..., -0.45922962,\n",
      "          -0.53050019, -0.59445092],\n",
      "         [-0.00981025, -0.05308692, -0.10626427, ..., -0.46186457,\n",
      "          -0.53532785, -0.60128437],\n",
      "         [-0.01754027, -0.06057583, -0.11362992, ..., -0.46533096,\n",
      "          -0.54087078, -0.60872287]]],\n",
      "\n",
      "\n",
      "       [[[ 0.08994172,  0.05942492,  0.02095945, ..., -0.50629992,\n",
      "          -0.52754852, -0.549702  ],\n",
      "         [ 0.08737299,  0.05807383,  0.02111732, ..., -0.48827398,\n",
      "          -0.50930199, -0.53113927],\n",
      "         [ 0.08310802,  0.05521583,  0.01999569, ..., -0.46859059,\n",
      "          -0.48948181, -0.51106003],\n",
      "         ...,\n",
      "         [ 0.41468543,  0.35512662,  0.28715006, ..., -0.03927762,\n",
      "          -0.04713417, -0.05335229],\n",
      "         [ 0.44239241,  0.38038584,  0.30953286, ..., -0.05604775,\n",
      "          -0.06434307, -0.0710696 ],\n",
      "         [ 0.46584379,  0.40167093,  0.3282722 , ..., -0.07098548,\n",
      "          -0.0797483 , -0.08698924]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.74376413,  0.67793523,  0.60521954, ..., -0.35232413,\n",
      "          -0.3730277 , -0.39002809],\n",
      "         [ 0.7077827 ,  0.64507128,  0.57588394, ..., -0.34071313,\n",
      "          -0.36107086, -0.37774966],\n",
      "         [ 0.66678923,  0.60761619,  0.54244011, ..., -0.32713767,\n",
      "          -0.3470491 , -0.36330974],\n",
      "         ...,\n",
      "         [-0.35640753, -0.33113357, -0.30051714, ...,  0.45827848,\n",
      "           0.51227955,  0.56167954],\n",
      "         [-0.37855243, -0.35190994, -0.31962625, ...,  0.48017898,\n",
      "           0.53667823,  0.58839747],\n",
      "         [-0.39898159, -0.37106631, -0.33723276, ...,  0.50053125,\n",
      "           0.55934866,  0.61321913]]],\n",
      "\n",
      "\n",
      "       [[[-0.53439516, -0.49194579, -0.44572472, ..., -0.50855444,\n",
      "          -0.5562018 , -0.60007187],\n",
      "         [-0.51601844, -0.4741739 , -0.4285795 , ..., -0.49326659,\n",
      "          -0.54022226, -0.58343802],\n",
      "         [-0.4947356 , -0.45360083, -0.4087432 , ..., -0.47612064,\n",
      "          -0.52242833, -0.56501892],\n",
      "         ...,\n",
      "         [ 0.08684404,  0.05577284,  0.01950281, ..., -0.2537444 ,\n",
      "          -0.24604396, -0.24024033],\n",
      "         [ 0.09794898,  0.06659576,  0.0299668 , ..., -0.24709462,\n",
      "          -0.23629472, -0.22788249],\n",
      "         [ 0.10858104,  0.07687524,  0.03981349, ..., -0.24132984,\n",
      "          -0.22788212, -0.21724007]]],\n",
      "\n",
      "\n",
      "       [[[ 0.25881997,  0.22181053,  0.17623878, ..., -0.73414477,\n",
      "          -0.80266215, -0.86597015],\n",
      "         [ 0.26759895,  0.23008845,  0.1839692 , ..., -0.7168169 ,\n",
      "          -0.78477087, -0.84753324],\n",
      "         [ 0.27785775,  0.2397259 ,  0.19291706, ..., -0.69799962,\n",
      "          -0.76532868, -0.82749278],\n",
      "         ...,\n",
      "         [ 0.09843472,  0.07695961,  0.05256171, ..., -0.16110386,\n",
      "          -0.16818979, -0.17427646],\n",
      "         [ 0.12312132,  0.09905157,  0.07180512, ..., -0.17901275,\n",
      "          -0.1889626 , -0.19745027],\n",
      "         [ 0.14461635,  0.11826172,  0.08850305, ..., -0.19486534,\n",
      "          -0.2072563 , -0.2177919 ]]]])>, <tf.Tensor: id=3546668, shape=(200, 1), dtype=float64, numpy=\n",
      "array([[0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081],\n",
      "       [0.00270081]])>), <tf.Tensor: id=3546661, shape=(200, 1, 120, 69), dtype=float64, numpy=\n",
      "array([[[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "         [ 0.00000000e+00, -5.62910792e-06, -8.43291468e-06, ...,\n",
      "          -5.26745837e-07, -7.96588620e-08,  0.00000000e+00],\n",
      "         [ 0.00000000e+00, -8.38084550e-06, -1.29751495e-05, ...,\n",
      "          -1.67810833e-06, -6.63003599e-07,  0.00000000e+00],\n",
      "         ...,\n",
      "         [ 0.00000000e+00, -3.36308236e-06, -5.30579005e-06, ...,\n",
      "          -6.88369176e-06, -2.92335560e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00, -2.16343288e-06, -3.30845564e-06, ...,\n",
      "          -3.31775880e-06, -1.29730163e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "         [ 0.00000000e+00, -7.78368479e-06, -1.33668757e-05, ...,\n",
      "          -1.23992176e-06, -1.09779806e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00, -1.33023294e-05, -2.35267991e-05, ...,\n",
      "          -1.18437282e-06, -1.26201408e-06,  0.00000000e+00],\n",
      "         ...,\n",
      "         [ 0.00000000e+00,  1.21166913e-05,  2.42933723e-05, ...,\n",
      "           1.48073224e-05,  8.93376267e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00,  6.26535980e-06,  1.25575126e-05, ...,\n",
      "           8.41308831e-06,  5.31293160e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "         [ 0.00000000e+00,  1.71314131e-07,  6.80653030e-07, ...,\n",
      "           5.46277827e-06,  3.66199850e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00,  4.28215047e-07,  1.30395336e-06, ...,\n",
      "           8.43234903e-06,  5.47018243e-06,  0.00000000e+00],\n",
      "         ...,\n",
      "         [ 0.00000000e+00,  2.88244620e-06,  7.80946863e-06, ...,\n",
      "           6.59785837e-08,  1.28922153e-07,  0.00000000e+00],\n",
      "         [ 0.00000000e+00,  8.32527584e-07,  3.22233635e-06, ...,\n",
      "           2.04721159e-07,  2.00746239e-07,  0.00000000e+00],\n",
      "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "         [ 0.00000000e+00, -4.28009488e-06, -6.08596605e-06, ...,\n",
      "           4.66284238e-06,  2.99864199e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00, -6.32902970e-06, -9.38770990e-06, ...,\n",
      "           7.60528111e-06,  4.69794381e-06,  0.00000000e+00],\n",
      "         ...,\n",
      "         [ 0.00000000e+00,  1.67448319e-06,  1.59283570e-06, ...,\n",
      "          -1.19112168e-05, -7.34925975e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00,  1.45587357e-06,  1.58205244e-06, ...,\n",
      "          -7.10256039e-06, -4.59163642e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "         [ 0.00000000e+00,  8.68777239e-07, -8.04175606e-08, ...,\n",
      "           2.09727096e-06,  2.08796062e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00,  9.67301655e-08, -2.24259011e-06, ...,\n",
      "           1.81179444e-06,  2.31399453e-06,  0.00000000e+00],\n",
      "         ...,\n",
      "         [ 0.00000000e+00,  6.92089090e-06,  1.42642150e-05, ...,\n",
      "           7.66475647e-06,  4.45019167e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00,  3.38753541e-06,  7.11502436e-06, ...,\n",
      "           4.47329849e-06,  2.66177738e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "         [ 0.00000000e+00, -1.01321886e-06, -9.84669144e-07, ...,\n",
      "           3.88241002e-06,  3.46206028e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00, -1.38985774e-06, -1.28903786e-06, ...,\n",
      "           4.33135795e-06,  4.24142786e-06,  0.00000000e+00],\n",
      "         ...,\n",
      "         [ 0.00000000e+00, -1.62693467e-06, -2.83283941e-06, ...,\n",
      "           6.56546871e-06,  3.69078139e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00, -9.84576423e-07, -1.58885298e-06, ...,\n",
      "           3.75810787e-06,  2.20681274e-06,  0.00000000e+00],\n",
      "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]]])>)\n"
     ]
    }
   ],
   "source": [
    "i = dataset_generator_2_rbg()\n",
    "print(next(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3576946, shape=(), dtype=float64, numpy=3.3931515309206384e-07>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from conv_laplacian_loss import conv_laplacian_loss\n",
    "s = next(i)\n",
    "cll = conv_laplacian_loss((s[0][0].shape[-2],s[0][0].shape[-1]), s[0][1][0,0])\n",
    "cll(s[0][0], s[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
