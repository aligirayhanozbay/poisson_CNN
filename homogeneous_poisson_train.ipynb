{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import Homogeneous_Poisson_NN\n",
    "from Homogeneous_Poisson_NN import Homogeneous_Poisson_NN_2#,Homogeneous_Poisson_NN\n",
    "from Lp_integral_norm import Lp_integral_norm\n",
    "from generate_cholesky_soln import generate_dataset\n",
    "from generate_analytical_soln import generate_analytical_solution_homogeneous_bc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Homogeneous_Poisson_NN(data_format = 'channels_first')\n",
    "mod(tf.random.uniform((1,1,74,83), dtype = tf.keras.backend.floatx()))\n",
    "mod.load_weights('Homogeneous_Poisson_NN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generator(n_batches = 60, dx = 0.1*(np.random.rand() + 0.01), nx = 64, ny = 64):\n",
    "    #dx = \n",
    "#     nx = np.random.randint(64,128)\n",
    "#     ny = np.random.randint(64,128)\n",
    "#     if np.random.rand() > 0.5:\n",
    "#         nx = 64\n",
    "#     else:\n",
    "#         nx = 64\n",
    "        \n",
    "#     if np.random.rand() > 0.5:\n",
    "#         ny = 64\n",
    "#     else:\n",
    "#         ny = 64\n",
    "    batch_size = 125\n",
    "    for n in range(n_batches):\n",
    "        if np.random.rand() > 0.5:\n",
    "            yield tuple(reversed(generate_analytical_solution_homogeneous_bc(output_shape=(ny,nx), nmodes=(32,32), max_random_magnitude=1.0, domain = [(nx-1)*dx, (ny-1)*dx], n_random=batch_size, expanded_dims = True)))\n",
    "        else:\n",
    "            yield tuple(reversed(generate_dataset(batch_size, [nx,ny], dx, {'top':np.zeros(nx),'bottom':np.zeros(nx),'left':np.zeros(ny),'right':np.zeros(ny)})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Homogeneous_Poisson_NN_2(data_format = 'channels_first', mae_component_weight = 1.0)\n",
    "mod((tf.random.uniform((10,1,74,83), dtype = tf.keras.backend.floatx()), tf.random.uniform((10,1), dtype = tf.keras.backend.floatx())))\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "#mod.load_weights('Homogeneous_Poisson_NN_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generator_2(n_batches = 60, dx = 0.1*(np.random.rand() + 0.01), nx = 64, ny = 64):\n",
    "    #dx = \n",
    "#     nx = np.random.randint(64,128)\n",
    "#     ny = np.random.randint(64,128)\n",
    "#     if np.random.rand() > 0.5:\n",
    "#         nx = 64\n",
    "#     else:\n",
    "#         nx = 64\n",
    "        \n",
    "#     if np.random.rand() > 0.5:\n",
    "#         ny = 64\n",
    "#     else:\n",
    "#         ny = 64\n",
    "    batch_size = 125\n",
    "    while True:\n",
    "        if np.random.rand() > 0.5:\n",
    "            soln, rhs = generate_analytical_solution_homogeneous_bc(output_shape=(ny,nx), nmodes=(32,32), max_random_magnitude=1.0, domain = [(nx-1)*dx, (ny-1)*dx], n_random=batch_size, expanded_dims = True)\n",
    "            yield ((rhs, dx * tf.ones((batch_size,1), dtype = tf.keras.backend.floatx())), soln)\n",
    "        else:\n",
    "            soln, rhs = generate_dataset(batch_size, [nx,ny], dx, {'top':np.zeros(nx),'bottom':np.zeros(nx),'left':np.zeros(ny),'right':np.zeros(ny)})\n",
    "            yield ((rhs, dx * tf.ones((batch_size,1), dtype = tf.keras.backend.floatx())), soln)\n",
    "def dataset_generator_2_rbg():\n",
    "    batch_size = 75\n",
    "    while True:\n",
    "#         nx = np.random.randint(64,128)\n",
    "#         ny = np.random.randint(64,128)\n",
    "        if np.random.rand() > 0.5:\n",
    "            nx = 64\n",
    "        else:\n",
    "            nx = 64\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            ny = 64\n",
    "        else:\n",
    "            ny = 64\n",
    "        dx = 0.1*(np.random.rand() + 0.01)\n",
    "        if np.random.rand() > 0.5:\n",
    "            soln, rhs = generate_analytical_solution_homogeneous_bc(output_shape=(ny,nx), nmodes=(32,32), max_random_magnitude=1.0, domain = [(nx-1)*dx, (ny-1)*dx], n_random=batch_size, expanded_dims = True)\n",
    "            yield ((rhs, dx * tf.ones((batch_size,1), dtype = tf.keras.backend.floatx())), soln)\n",
    "        else:\n",
    "            soln, rhs = generate_dataset(batch_size, [nx,ny], dx, {'top':np.zeros(nx),'bottom':np.zeros(nx),'left':np.zeros(ny),'right':np.zeros(ny)})\n",
    "            yield ((rhs, dx * tf.ones((batch_size,1), dtype = tf.keras.backend.floatx())), soln)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60/60 [==============================] - 78s 1s/step - loss: 0.8998 - mse: 0.0535 - mae: 0.1204 - val_loss: 0.5849 - val_mse: 0.0157 - val_mae: 0.0834\n",
      "Epoch 2/50\n",
      "60/60 [==============================] - 69s 1s/step - loss: 0.8909 - mse: 0.0521 - mae: 0.1391 - val_loss: 0.2832 - val_mse: 0.0094 - val_mae: 0.0836\n",
      "Epoch 3/50\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.7574 - mse: 0.0503 - mae: 0.1570 - val_loss: 1.8222 - val_mse: 0.1221 - val_mae: 0.2331\n",
      "Epoch 4/50\n",
      "60/60 [==============================] - 68s 1s/step - loss: 0.7685 - mse: 0.0395 - mae: 0.1226 - val_loss: 0.5131 - val_mse: 0.0167 - val_mae: 0.0882\n",
      "Epoch 5/50\n",
      "60/60 [==============================] - 71s 1s/step - loss: 0.5965 - mse: 0.0260 - mae: 0.1096 - val_loss: 1.2541 - val_mse: 0.0725 - val_mae: 0.1619\n",
      "Epoch 6/50\n",
      "60/60 [==============================] - 78s 1s/step - loss: 0.5573 - mse: 0.0379 - mae: 0.1221 - val_loss: 0.1339 - val_mse: 0.0075 - val_mae: 0.0592\n",
      "Epoch 7/50\n",
      "60/60 [==============================] - 71s 1s/step - loss: 0.7138 - mse: 0.0467 - mae: 0.1357 - val_loss: 0.8517 - val_mse: 0.0292 - val_mae: 0.1089\n",
      "Epoch 8/50\n",
      "60/60 [==============================] - 72s 1s/step - loss: 0.5439 - mse: 0.0186 - mae: 0.0866 - val_loss: 0.4570 - val_mse: 0.0158 - val_mae: 0.0911\n",
      "Epoch 9/50\n",
      " 6/60 [==>...........................] - ETA: 1:15 - loss: 0.3911 - mse: 0.0090 - mae: 0.0653"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d314f878ba11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegral_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_generator_2_rbg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_generator_2_rbg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#maybe incorporate delta x and domain size information? via [dx, dy, Lx, Ly] -> dense layers -> einsum into conv filters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/.conda/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1245\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m           \u001b[0mreset_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m           output_loss_metrics=self._output_loss_metrics)\n\u001b[0m\u001b[1;32m   1248\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, reset_metrics, output_loss_metrics)\u001b[0m\n\u001b[1;32m    293\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    296\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    243\u001b[0m                         'compiling the model.')\n\u001b[1;32m    244\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         model.optimizer.apply_gradients(zip(grads,\n\u001b[1;32m    247\u001b[0m                                             model.trainable_weights))\n",
      "\u001b[0;32m~/.conda/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    939\u001b[0m       grad.dtype in (dtypes.int32, dtypes.float32)):\n\u001b[1;32m    940\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m   \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" vs. \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m   \u001b[0msx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m   \u001b[0msy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36mbase_dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbase_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;34m\"\"\"Returns a non-reference `DType` based on this `DType`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_ref_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_INTERN_TABLE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_enum\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36m_is_ref_dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_is_ref_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m\"\"\"Returns `True` if this `DType` represents a reference type.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_enum\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "i = 0\n",
    "initial_epoch = 0\n",
    "mod.compile(loss = mod.integral_loss, optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3), metrics = ['mse', 'mae'])\n",
    "mod.run_eagerly = True\n",
    "mod.fit_generator(generator=dataset_generator_2_rbg(), steps_per_epoch=60, epochs=50, validation_data=dataset_generator_2_rbg(), validation_steps=3)\n",
    "#maybe incorporate delta x and domain size information? via [dx, dy, Lx, Ly] -> dense layers -> einsum into conv filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.save_weights('Homogeneous_Poisson_NN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 0.05#0.1*(np.random.rand() + 0.01)\n",
    "nx = 128#np.random.randint(64,128)\n",
    "ny = 64#np.random.randint(64,128)\n",
    "batch_size = 100\n",
    "soln, rhs = generate_analytical_solution_homogeneous_bc(output_shape=(ny,nx), nmodes=(32,32), max_random_magnitude=1.0, domain = [(nx-1)*dx, (ny-1)*dx], n_random=batch_size, expanded_dims= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 64)\n",
      "(128, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEICAYAAABCnX+uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnX3QLFdd57/fnud57r0EAcmNkCUJwSVrFVK7Eu4GKaooSt6CIrFWLMKWGi2slEpWWN3SgCu4UaywtaXCgroRokFZAhVErxrNRl4KsQQTYngJAXMXsHJNlrxBIJCb53lmfvtHn3O6+9fndPfM9DwzPfP7VE319DmnT5+e6TnT/e3fC0UEhmEYxnDJlj0AwzAMYz5sIjcMwxg4NpEbhmEMHJvIDcMwBo5N5IZhGAPHJnLDMIyBYxO5MThI/irJP172OAxjVbCJ3Bg0JM8lKSS3lj0Ww1gWNpEbC8MmV8M4GGwiN3qF5JdJ/hLJTwP4JslzSL6f5L0kv0Ty50ptLyB5M8mvk/wKyd905c8jeTLS7wsiu/yoW36N5EMkn72wgzOMFcUmcmMRvBLADwB4PIAPAPgUgCcBeD6A15J8sWv3FgBvEZHHAPjXAN43w76e65aPE5FHi8jfzzVywxggNpEbi+CtInIngKcDOENErhCRXRH5IoDfB3Cxa7cH4Kkkj4rIQyLy8WUN2DCGjE3kxiK40y2fDOBfkfyafwF4PYAnuPpXAfg3AD5P8iaSL13CWA1j8NjDKGMR+JCadwL4koicF20kcgeAV5LMAPwHANeRPB3ANwE8yrcjOQJwRsu+DGNjsStyY5H8A4Cvu4efR0iOSD6d5L8HAJI/SvIMEZkA+JrbZgzgnwAcJvkDJLcB/FcAhxL7uBfABMB3LvZQDGN1sYncWBgiMgbwgwC+B8CXANwH4B0AHuuaXAjgNpIPIX/webGInBKRBwH8rGv7L8iv0E8igoh8C8CbAPydk2++d4GHZBgrCS2xhGEYxrCxK3LDMIyBYxO5YRjGwLGJ3DAMY+DYRG4YhjFwlmZHfvrRo3LOOefAP2sdYdJj71JZdDI1bn3o21I/xUNjdm7ZuMOpipdO7aC7fwrhkKi3aeij1lZtQ7XeRLKvKfoYONL6GXSHXX9rpXa33Pqp+0Qk5UvQiewxZwn2T3VqKw/ff4OIXDjP/g6SpU3k55xzDj780Y9hz83fj5Vv5W9ETeic4qbBb6uXk2qf1PVAcdK4MupxTLveQK3vJiaJtqkfQ6LvqfY5B5L6vnR5bGLI4tuGPhPLWn25f90ma+4rehxtY9f70ExzDq8oC53I9W8u/G7Hocnhx57+z3PveP8Utr7rZZ2a7t36B0fn3t8BYp6dhmFsBiSYjZY9ioVgE/mGIMwO7KrcMFYTItvaWfYgFsLSJnKC2Bll2PF/kKf282WbtBKZjDjej7fpegtX2Ua1mai+pINM0zDWvM9xtFhiMopvq7aRsS+fRNuL3kek71qbGUhe4SiZpNZuazsvH5XKfRvVNnNtU5IKQ3np9j9LtVF9ZFvVbWNSS4scE/ZRHGx9PLrOUZNjepBh2mQQ/bOYdHi+k3IcnDRs2nWbzI135L4LP/ytvi+e7YrcMAxj2BDqwmGNsIncMIzNgERmV+TGoMmytAWMMTiE7GDGZ2hMWlkQQc7TmrTXJVU5o7q2Mh2cKL29TfcubxOWXmtWplC+fJyoL5HUoN02dR27rnsXWrjaf2pcLePV/afG3kjsx6A18ZHSu9U29Bq5178BwD2IKrb1JoMjtc1OpT60Lz3Ioq8L+89P9cIMcVRpV2jlSlNHWkeX0Va1bRezSO8v0VELb9K7dV04nRPze0oLn+bvoEkTz8dQb6C30S3GrmDi3mTusLJRz2abppEbhmEMG4LFg/M1wybyDYGjUfWq3DA2jU2+Iid5GMBHkWdo2QJwnYi8UbU5BOBdAJ4J4H4ArxCRLzd3nN+pBp1PSSdeBamZ9zXJIS0SSk1yGe+FvmQ/fy97u5VtZV+ta3NAX16RLhImg1PKIfl49lTb6jaT3f3Kuoyry7Hb3q9XxuPbTqmdM+KByZGWVrJK28zJH748285PvWynOAXD1VJWlVZ46Ei+1HKMlmJKV1tahuF2te/Qx8i10+aIZeuGIMdU5ZfwPSW8SDlS7WNttKmirtc6RESS8RKLVmG0yuHN/LqYG7ZJKLUxzCCppPYhob7/ZwAbO5EDeATA94nIQy7t1sdI/pXKeP4qAF8VkaeSvBjAmwG8YgHjNQzDmA1ybc0PW58mSM5DbnXbvfRf5UUArnHvrwPwfLLH4AyGYRhzQuRX5F1eQ6PTY2GXNPdWAPcAuFFEPqGaPAl5xnSIyD6ABwGcHunnUpI3k7z5vnvvnW/kxlRo6WMevnHnV3rry5gRC7cwPcww2trp9BoanR52uiS630PycQA+QPLpIvLZUpPY1XdN4BKRqwBcBQDPPP98oUgy2mChZydMC4GgjQcX/VQEQ9fO6+BwunfQn1Fo4UUbry2Pq9u06dzlttqNfkqdGwDGu3uNbSfj5j7Ge/u1PsMxaxPKKfCTObUJoCNo4aG+uvQa+aiskXvd3C9dn15H1/XcOZwvt3cq60BER99Wmnmo3672obTzfIdujJk7z7K4Zi6ZMkf0z3si7v7U2wat3D3PYdxMsfKj8ud56nosYZ7YRSv3JoCzmBvOSqY1/t56dnB9NfKpLtNE5GsAPoI8+3mZkwDOBgCSW8izpD/Qw/gMwzB6geDmSiskz3BX4iB5BMALAHxeNTsO4BL3/uUAPiR9/lUbc9OntGIYQ2VdJ/Iu0sqZAK4hOUI+8b9PRP6C5BUAbhaR4wDeCeCPSJ5AfiV+8cwjSiRsqJkaoi6ppMwLa6aFbn2yW8oWotoEicXLIHo9ZaYIYKLkDL2uTQK1DOJlkvxQqtLJJKzHJZeJMimc7I4r5Xld9T/We9SF+ogMA8T/DLJR9X6Y7v44C1IKK9t6KWak5BIAyHZyOWPkpRMlw2wd3nHtnCzj5JKRK/dLIC276HIvrWSuXJTUAtTlliChZO6z9h6e/rzzXqThMyk+n3B6s/oZBwfn4tNwy6rEwphcI3EZJlRPEe2wZjKo2raZDDbR2veiMy1tsh25iHwawDMi5W8ovT8F4Ef6HZphGEafbPBEbhiGsQ6QRLY9PIuULgxOOO01y83+XnubNaHPAETf/Mo3e+vrW/c82FtfxmxM68XZxLjPzvqG6/uwc3WvyL3uHcnAQ+Wur/XzlJlhzcQQKLTxRx6u1CU1ca+vB53dadN7ha69f+qRfBulkY9V25SJ4KRkFun7123Gu950UKrr4+r6xNVLSQcPOnpNG+/2I+SIYTKn0si1Np5lVY3ca+qZSw012s7CZL51xOnTwa3f6elBG8/rg1autPOyRr515JTa1mnjR07Ll0ozn7jvOURWLJ0jQTcPoQL8+ed+Pu489O3qScCLzyho4S269lTUsg7FtWatjUulzo9Lquu1PtqH0zaZpy7Fspoe379mPsRJugurO5EbhmH0TKaN1deEwUkrxmzoK2fD2DRIglm3V4e+LiT5BZInSF4eqT9E8r2u/hMkz3XlLyT5SZKfccvv6+PY1uuKXHtbpiQVJaeU69pkmfEptXT1fh2oSyhaHpko80Pd3ssi+TbKRHHXyzFxKSWs73mzQ6lsX24T6nqIfpgFM8O4lKLNEreObFXaA8D24fxz8bKL33a0nUtVo8O5dDE+4qUVtx6RVvz3sX3aEVeXf7ZbteiVfum8QiOfRc000MswXp4JO2WlXd2kECWrQi+t9CixKFJWhkV0Qd+uJLu5t1plq5sKzr7/FJNa9Mb+9fZRD8+KnCn22wG8ELkz5E0kj4vI50rNUoEE7wPwgyJyF8mnA7gBeYiTubArcsMwNgOiryvyCwCcEJEvisgugGuRBw4sEw0kKCL/KCJ3ufLbABx2YcDnwibyDcE8O41NJ49+2HkiP+oD/LnXpaWuQpBAx0nUr6q7BBL8YQD/KCKPzHtsKyOtiPJcqzdQySIqZSpgVPC6VF6Z2nuznBtTSyqPnHJdV6WT/Ycfqax7uaQsrey79977MmW14uUQLZ/sP1xYwPi6lHTSJqkUnp3FbWqQVhK3rmNVPlJWEFnEKiJYqWhPTl3uZJmtU947s/iD8cc92hlVtt0+7KxT/DGfyj9XL7V4qWq7Ih9VPVy3VHakcOJ3yFfqg5z5kYZPJySpcOuseq9KJCCcSOIPtU8rFoX+nlMWKkAhqaSklDa1Yx7rQ6+yhVwzC4iaFTt3E9wnIseSHdWppQBpakPyu5HLLS/qOqAmVmYiNwzDWChEpweZHQhBAh1nAbgr0eakDiRI8iwAHwDw4yLyf/sYkN1vG4axMfSkkd8E4DySTyG5gzy21HHVJhpI0AUg/EsArxORv+vruGwi3xB0cCvD2DRIYLTFTq8mnOZ9GXKLk9uRBxK8jeQVJF/mmr0TwOkukODPA/AmipcBeCqAXyF5q3t9x7zHtnxppU0TbHDJLxJHVJM/pBIlh0QKSg8vv2/Txve/dcqtV80QvTcnUGjghVbutfCqrq1NCYM35m4psUTLNloDH++7eic07nrPz4oOWpXzOjp0Bsr/CUE/36vW+fIdb3boEwS7Bn785T+YrcM+2YT3+syX/ti33dKbLm41JI+eqLJUEujg59fg8Rc0b3dOBO9Af/6EZBFqPN60UOrPdUIUQ6WNR6Mb9kTKS7Pp609p48koiDOYDB5kVsi+9iUi1wO4XpW1BhIUkV8H8Ou9DKLE8idywzCMA4Dk2np22kS+IYw4/ZW3YawbPT3sXDnWcyIPkooyWWzIs1nkr/QmbtNJKjHzw/1TVTNDb16nTQq1GeKk4tmpJBXf1kkohXQSl1L6lFZiMruXUApJJV7uJZaR83487HZa9uz08tDIHetoJz/W0V4uZQSzyUggMCDhcZrIGVrLIeoktSCxlKUWVcYg1bn9TZSZoQr4Fv14tTmt9vAMkstIrc8vuTQliwgmiWEdybZNfc42nsVPsjaRG4ZhDBnGfSDWAZvIDcPYCAgi21pPQz2byDcE08iNjYfrG8Z2uRN5U7YfVaf1x3Kb4JqvdG7R7tepyHdAkTBCRywMWnlVG9/71sOqvEhEsOe08UITVxp5QhPXenh5m71JVRNv08K1dh7TyOcxOyzKtEbu1/POvTbux+PX/Rh2dMg7lMMNOBf9xECLpBXVyIrl9+Pt/PPL9nR4BBdp0Sd6zvLvkfsuOYRPEgFEnq246IcotckrqksofRtls8ODvzJcRPKeWbRx/2noT0B3tYjrjoM0dTxI7IrcMIyNIA+atexRLAabyDcEk1aMjceklSWi5ZcZki8XkovatiSt+NvlcOvtE0aoW3JvbqglFS+n5HW+bVxiSXlphnb7xTi1lNK2TEkr5SOfVlrRkko5GmLmboBTkorfh++jaZ+j/Wou0dGOk0dU0org8bnnzRSrkR+BQkrJ9nxu1fxUD1LLdvV7zXa23L6dbFKW3ZLmrMqsVUstvr7hKrDm4anNDL3esGRJYB5ZJiWlpMoXB3tNQr5KrP5EbhiG0QO0K3LDMIzhs64OQa33GSTPJvlhkreTvI3kayJtnkfywVI0rzfE+jKWx3reUBpGd0hglLHTa2h0uSLfB/ALInILyW8D8EmSN6pEowDwtyLy0lkHEjUvLBNLEKyjH6Y0cGWGqM0Vq2XVZT1xcnWpTQ2Bujbu22gzw8IcMd+XNjEsv3943E0b35OqNq418zLaVT9Fyg2//N5/8n5/fulk7qjpYn0/Xl/P16mTRKssSCGSossy5JM2523V95j4fvUybF86l6b9WReu+emIikaaRZhJeoY4SXehdSIXkbsB3O3ef4Pk7cjz0emJ3DAMY2Uhhnm13YWpNHKS5wJ4BoBPRKqfTfJTyFMe/RcRuS2y/aUALgWAs88+W1cbC2QnY/Sq3DA2BRLY2XQXfZKPBvB+AK8Vka+r6lsAPFlEHiL5/QD+FMB5ug8RuQrAVQDwzPPPb5xVUkmYk8mZy8RkGCDi2RlJ1utvxfeqCZ19ImWfQLlIAlGVS4C6ueG0kkp5wm2TVPzSH0lbNMQybdKKl1R8uyZpJVaX7z9fanPEYgz18fiyTEkqE7X0FNEQy99ntUxLJ23EIikuBW922MGTRRZoougvZGe5FtAj9+vTGxLPBwlsrekVeaezleQ28kn83SLyJ7peRL4uIg+599cD2CZ5tNeRGoZhzAGxwQ87mQcneCeA20XkNxNtngjgKy656AXI/yDu73WkhmEY88BhTtJd6CKtPAfAjwH4DMlbXdnrAZwDACLye8izRP8MyX0ADwO4WOaJNG/0Tp8u+mORinenYQyB/Ip8RSSznulitfIxtFhgicjbALytr0F1pimaIZDMDBRrH7TxsU9mrMzTJnpZ1WvHpaw+fttxIqqh3yaljZc1cm0+OKs2XtbDu07oWhv3p0H+pyC1soNGZwiaB/bour2IxMmL7Lt8kXqQ8XiWMaVu8hW5YRjG4MlIs1oxhs2I7OwAZBjryrpKgqs/kc8S7VBLLFO00xESpzVb67TfKe5f2ybfromUZ5nEU4mUyz+GdNLlVFLm+D5i21I1zkICCZVQIiSYKK62OKqWJZMu7/jEEr68Kflylli6ei17RPTYII24Y6xJJb0kV86Xkxm+85B4YQ3/9L2L/jqy+hO5YRhGT9hEbhiGMWDW2SHIJvKeyEZZsFZZRfrUyPt09+9zXKPtLCSbmBdubUP299obduosm0kiPPA+1xzCHnYujjZNcA7NUGcGikU9DG0Tbv1tZmlZScftmn2EOmRgA21ac8kpvVJeWIwWZoiFtj1r1MPiWL3Lva7bVtsU7arLndKVkd5PxqoW7jMFBd3b9+miHY5KUQ9HPhKiS6rslyOfZHlUrQ/a+NZO3oFfIp/M3UAqS/rlKBHd0J2zFf172vO8y3kf9uP09sTXOs3f5Dq7f5hGbhiGMXC8i/46YhP5hmDJl42Nx67IV4fy7SqzgwvcH27Bw7JqAlc2lfO3+hKi8lVnUG/SuD3uEgeu6kFZQ+X3Hblx1D07Y7KLr6smUA7H0cH80O9XSyhaevHrenmk9LntbFelEp1seetwfrpuHfFySTWhREVicWaF2U4uj2iJZeTLvfnhdr5ek1PKdUpiCVKL30aZFhbrEYmlq2SoZZoO23mzQ/2/7WUT/3hDQvv2Yeg2fUgwbcmX+466bPHIDcMw1oB1ncjX8xGuUWMZsVAMY5XIXGKJLq82SF5I8gskT5C8PFJ/iOR7Xf0nXFIekDzd5UB+iGRv8alW5orc3zoSY7Xu8F5yMa/NKSUWb21QvnPT0kmmrBv8LfpI5ez08sl2RIBu8+DkKL+5pAuuNdrP133uyvL7YonocixVSSV8XKgmhyhTDC8e+MrLJJlaj3tj5ut1iSVe7iWV7ZL3o5dMMi2peCnFSSfbSmIJ64cLi5PR4UOVsq0jO668usx2Drud5+teJuF20ZeWULzUoj06JXM/p6wqg1StV9SHnGrb4kpeTiLR5sk5jUTh5Y6kBUyLpBITCfW0qNv49YULpT1p5CRHAN4O4IUATgK4ieRxlcf4VQC+KiJPJXkxgDcDeAWAUwB+BcDT3asX7IrcMIyNgCBG7PZq4QIAJ0TkiyKyC+BaABepNhcBuMa9vw7A80lSRL7pIsqe6vPYbCI3DGNjyMhOLwBHSd5cel1a6uZJAO4srZ90ZYi1EZF9AA8COH1Rx7Uy0oqxWCz6obHpEFM9K7pPRI41dKXRP64ubXpjuRM5s3rC2LAe1w4ZM+VKeN4hRLKrRqsLBn1lEzOvibttgjbuTAVHe/n6ZLuux7bBh6seidmeM5fbdgknnJDsE0+MSkkqdvabk09oM0OdYKKaWEKbHcbHGzMzLJc3eWWmzA61WeL2Ifc5l0wGvdYdzAmdeWFNCz/ivwOnnR92zy9K38nW4bgmvn3akXz9UK6h81CukVNp5fAmhSiZFyrTRF8etHHvYRnW0yaDNXPCRFvdLubFqbVxbVbYZnbYpHu3tekSJGBlAgmwiJQ5JycBnF1aPwvAXYk2J0luAXgsgAf62HkMk1YMw9gIiPzhepdXCzcBOI/kU0juALgYwHHV5jiAS9z7lwP40CLTX5q0siGYtGJsOlNKK0lEZJ/kZQBuQG5sc7WI3EbyCgA3i8hx5Anr/4jkCeRX4heHcZBfBvAYADskfwjAi5TFy9SszkTu/wWl6u3ob1PpI72VAhWJ+MBHLkqdNwub+GBZTqLwQbJ8NDvtoYd6ooHMbZM5M8MsSCqHWg9Fe316M7r9U3lfIZenlw4mW5Vy3y4vq8otWmqp5+hMeXbWpZWwD9cmZX5YrOfLqrRSbaulle2QsKEa6CrIIjvF1U9RNoq21RKLl1S2TzvslkeKvkJZtc5LLFpS0aaFrEgrbpvtqokilIQio61KedSUkFWZL+mp2UFS0cwqqZSlj8KUMb6PlZFJZoHsS1qBiFwP4HpV9obS+1MAfiSx7bm9DKLE6kzkhmEYC4QoImuuGzaRG4axMayrh7NN5BuCaeTrxURkba8uFwUJbHfMGTA0lj6Rh7lFmxn6Bt5d3euOpawoTJgfJs0Qt5SGvrdb9FVz0Y+bIWq8u3818e+u68OZFe44vd1dDnhtfOw0YJ9ZyGvp5b7aTBR9GIAdlxij2QwxHvVQ0zUKIlA3L/STS5EMIqus+2PUJoYAsPPonUqZ18gz5ZqvtXH/3CJmfui18a1H5W2zI6fl4zrsll4jr2nmpQQTh6o6OkbK7DCYuWptvK6Dp+pakzJH0FEOtfY9TujdWhuvmjI2t9V0uTZI/d/obfuOdlgbB0xaMQzDGDzrKq20/u2TPNtF67qd5G0kXxNpQ5JvdZG+Pk3y/MUM15iVdT2BDaMrRDf3/CFetXe5It8H8AsicgvJbwPwSZI3KrvHlwA4z72eBeB33bKV4JWmzbK8lKFuNauene4DD1Hn4p6cxVJJL+UId06a4GjfLavRD/0H5Q0DUzk+y4wz31fVs9Ob0QUzRCeXBAmmZJI38XV74/g2rtxLLRMvtex7qaV6m10Z34zSSvlE12aFfl1HMEybHxYmoNoksWZ+qLw0vaSiTQ3z9wlJZUdJKMGkUC23I56dWlJp8+SMySTJaIcpyaVqdhhLGtEmqWg/FC2pxCSNlKQyy2OW8BNntz6K8fY8ofYU/XAVab0iF5G7ReQW9/4bAG5HPUDMRQDeJTkfB/A4kmf2PlrDMIwZyTXybq+hMZVG7oKjPwPAJ1RVKhrY3Wr7SwFcCgBnn10OVWAYhrFYvIv+OtL5qEg+GsD7AbxWRL6uqyOb1G6gROQqETkmIsfOOHp0upEac2Ea+XqxaAuPtYTAKOv2GhqdrshJbiOfxN8tIn8SadIlGljLThLRDkN91QwRAMRl2PHmhFTmhV73ri/H1WXp/WjS7IKvP7BgtlgxP/Rlj+RdB70937/PLuQ189GO0zZ3nYnhdqEbB918t2q+58v9NuJ0ZK+Ze61cwrJQOye1ZNDixhuf7b3eXRwX63VZ1cywiCYZ18qLBMrFse48ejvetqM2HnPRr2niWhtPuOhjq54hSNSzmOCSn8ruo5/7ADW3fh3BU4IJ4+za+HjSrInr7cv0qY3X+56/j3lYZ/PDLlYrRB4A5nYR+c1Es+MAftxZr3wvgAdF5O5EW8MwjCXQW4aglaPLFflzAPwYgM+QvNWVvR7AOQAgIr+HPHjM9wM4AeBbAH6y/6Ea88BRVrkqN4xNY52vyFsncpdfrvHoXZzdV0+zYyHzV+p+yyeBCFaILhpiyZSr5tnpoyHWJJZqNMQuX6VOBOulgony5Jxsu4iGe0XEwmw3fz9ypot+Ah2HxM15FMaJa+c9O73kMi4llhjvuTpXtuciI26NqyaMXh6pSyuTSn25zpMypaR6MFRILGXzQy/5eCklHu1QR4LUJoYAsH3aTmW/ox3vyVlNpFwkiah6dm6VzA+zw4/Kl9rs8NCR6rqXVA7FkzDnnSQkFS+DaPPXRDTESp3uU0kqXh5pi2hYbuO36SqlxH57bZJKKsFzE6nJ0/eVBRlpsdpL7qK/oRO5YRjGurCmF+Q2kRuGsTlkfTsZrQjDM7TpEEzIqJOySJkF72lpLI9UvtVZ2JQnJ0R+Rd7lNTSW/osM2l/MBR8o/mp85iAZR0y3vJ7u9VlvQuZOUZ/tx+/T9z0umx86F301vpF35x+dcrusZhLyGnnmdG8AkMNa83aaudLC27TzSt2ud98fVdZDJEWnpXv3fu/a7/V3idiaaa08RRb5E9Au9oVrvtLIfbRDX6+iHlZd9HN92odF8JElfflW0MTjZojZTqGRh/ALW2qpwzbohMqhvmTmGvRsZSKbMCVMaujltkobn7gzb6IyO6Wy/ETb+PG2RD30TCLv+9DENVoL13369YOwFhmi12YXlj6RG4ZhHAgDvdrugk3kGwIzRq/KDWNTIIZpI96F1ZnII0H4AQT7w8LTc1zbJtQFM0Qnk+hEEn6zskenphYp8ZQrdpLK1p7bhTPzC9JK6VY8mPx56WQvUe5NCauSS1RacX1s71bNHfcf3nPrVTNFb5bob9Wr5od1k8QmtL6eVbxYnWQSEk538/D0ySG8iWFe5hJE+GQewfzQSylVScWXjw7l67GIhYXnrZNOdJTDUK4iHJbPw5EyERx5mabZ3LBmloi6HBMkFekmqfj1cuTKNillmqQQbVKKrp1mWuxDppkXk1YMwzAGzprO4zaRG4axGWy0Z+fSqEktDUZSSo6pWcAEyxOfu3MHNbT8ouv97bG3hnD5PkfOMibbLvJ/ek9JL5F4iUBLK6PxuNJelMQCFBYvWnbx0sr2aXvR8iCxKE/Pcl1XqxVPk2dnppJnaOuVkPvUSy/eQmWnkEO01cqoJq0cqtb7HJ1bkUBX2lrFSy2p4FheUvGyyaguh2hJpcjZmZBUdOIJAOK3VRJJynNTSy2pPJyVbWvl9bZlYpJH1zOjqd20U+ZBmEGu6Ty+whO5YRhGz6yrF4pN5IZhbARc41RvNpFvCNmIU0sphrFumLRyQAR9WxKKWembqGvh3vuzmtDZ66LeZBBEaQkRAAAfaElEQVSZi4JYMgvTunnQylXCZp3EQvZzjbps+ibek3SnmshCJnFNPCyVtp5vOo7WjZV3aEpDnyjTx/L7csRG3SYGI6lTgqfrSJkbKu/MIkriVqU+K5kfeo28aLtdaRN0dRWxUCeNyOtckokt38fh6DbYynV3CRq5172L86HQyL2JotLEdRRO5fkppXM2FdVQl6ciGeqkEbE2tfpExaL/1ttSKLftv+9oiIRJK4ZhGIOHa3pJbhP5hmCJJYyNh+YQNAgKqUV5gyqJJbQvJ1TIvOzipQDXh6tmVjVP9DB8gqW+E7lB/TnkpRfohA5KggHqAbbqAbeavUa91FI+Vt12osaRmvBj0kqmcpaGZaI8U9KLXwLAyJkiFrKMkmna8m0eKnJ21nJ0KkklmBJuVc0OC5PCklSWNC9UAbCCpKJMDEtySJuZoTdH1Ns2ySfzSifTRG6YZSLUEsuyntQQ65uEfK0mcsMwjCbWVVpZV+3fMAyjQu7Z2e3V2hd5IckvkDxB8vJI/SGS73X1nyB5bqnuda78CyRf3Mex2US+Iej8m4axibDjq7EPcgTg7QBeAuBpAF5J8mmq2asAfFVEngrgtwC82W37NAAXA/huABcC+B3X31wMR1oJpoWlCYlVM0MdhU5rclRLNERBLLTxrLoedG+fzKJqlljpP0yeVW0+pY1rLR0AuOPq9qtRF73mvdViwqjNFytt9TYzPAzNlCYexp3QzDNnjuhNCssaedDCvRlfcKevJkQuTAdd+aGqVl5uE5Itb3szQ6eFh2iHVW28ZmIItLve60iGCVNCoB7NUGvg/ivQWrnWwZt05kVGK9Z9T6OZt5sbTj2cKWFfsVYuAHBCRL4IACSvBXARgM+V2lwE4Ffd++sAvI25rnMRgGtF5BEAXyJ5wvX39/MMyC7TDMPYDDqmeXNz/VGSN5del5Z6ehKAO0vrJ10ZYm1EZB/AgwBO77jt1AznityYC2ZZ1UrHMDYMijTnIqhyn4gcS3UVKesSql06bjs1S5vIKQL2dC9V8/D0XqEJT8/ggVfy5tSfrr+9L7xBlYTiJ8VxVRYpvxdthpjYV/gU9D5K4wjR+Nz+qPrWkkuQMpQXaWW/3vxw3PnkrpGNqvKellSK40h4fpa/A+8dq7xpa2aG21XTQe21Wd5GRzXsLKlEc3Y2mxmmkkOUIyPoxBD+a9GRC7Wnp6aLfNLHz6tNifDjGIp9dtJjfDpOAji7tH4WgLsSbU6S3ALwWAAPdNx2akxaMQxjQ5D8Iq/Lq5mbAJxH8ikkd5A/vDyu2hwHcIl7/3IAH5L83/o4gIudVctTAJwH4B/mPbLWiZzk1STvIfnZRP3zSD5I8lb3esO8gzIMw1gIIt1ejV3IPoDLANwA4HYA7xOR20heQfJlrtk7AZzuHmb+PIDL3ba3AXgf8gejfw3g1SIy+y2xo4u08ocA3gbgXQ1t/lZEXjrvYIzFYS7664VIu+xhKES6XG137EquB3C9KntD6f0pAD+S2PZNAN7Uy0AcrRO5iHy0bMy+aHrRsLRW7s3FQpJmr8+WttFJl71O7TVprZkn3PDLdXWX/EjbaF/FjZJ+QBl+uz4h8NgdkzOD9A9zgtlk5AFnLVNRrUV3alq4dtHX0SN9O52hByXzQa+N++8kYWYYEihvK7NEoIhq6DXwKbXxclafVhd87W4/iWvl5TKtlWudXUdHjHEQuYzD46WOWnmZNt1cb6Pd5xdx2dGTRr5y9KWRP5vkp0j+FcnvTjUieak357n3vvt62rVhGEYXBJjsd3sNjD4m8lsAPFlE/h2A/wngT1MNReQqETkmIsfOOHq0h10bhmF0RNDXw86VY27zQxH5eun99SR/h+RREVn8Jbe/3yvcMKtj8xIKVAIF7x1aak/uu6KEmaFKuhzkk0jEQl8nSuYIHp5a7miSXhISTmFm6Nb3iuTPQMmLVUtCpfHIqFvUw7BdQ2IJKumkMCH0ZofKpFDJKNEy39ZLJwlJRSdQBgoZJJhtelkkeAGzMr5kfaksJaloKSXlrZlvq5Mox6WUZJKIA4odmCkj2a4SS5nVM02U+m9vTZh7Iif5RABfEREheQHyq/z75x6ZYRhGz6yrRt46kZN8D4DnIXdZPQngjXCXliLye8htJH+G+SXtwwAulr5zNBmGYfTBpk7kIvLKlvq3ITdPNFYYZqOq/DMH2c5hTHZP9dKXMRtmfjgDIo2B8obM6sRa0f+UiX9OKevawbxQRSjU24QodZPqdpNIImf/xDqYKvq2CfNEZaaYl1XND/XJo00YWSsvtXcZgGr7U9q5TgYdtPRSNiKtY9fiTrSdDaXtvVs8alEPlbmhNiUM+6pGNARKrvfKFLRNGw+RDWMmg5lyuU+U19zwKy76eVlKC9eRDFMmhkCTO78rVxp4073trPe9Xf4A/Dj60Mq7Us901P9ONlZaMQzDWA/6cwhaNWwi3xSybG2f2BtGZ2wiPyCm+aCDzOK3qUosQR7xfbqlBEmm2JdvE7ZV4/ASi+6rJnWUy1LrOtpgkyljyhwymEG6Y/aK0JYfnpc0SpJM8Ab1ER2ncyPgKOID2iahpOq9LFLu00soCRPFWgIJH9lQySIAIN4kUXlwhrZbO9Ftg8dnqa+ukoo/A1Jem+UybWbopQytLvSZJMKbATZJMloyWYbEsjB6dNFfNVZvIjcMw1gAhGnkhmEYA0fqd8NrwmbHI8826H9Me17OAQ+f1mNfj+qtr03CPDVmwFz0B0IQ7JSrfqiPaOZeE1WmjIWJotfVqxEVQ70PA1D+8vWJkIp2qOsjpowhg47Xz715odeJ/TbKTJHKlT+aHHoOm9owmWuTRh1F0uN1bq+Jl80O3WQejlW79afMDL2uHcvqM9ppbFOrd+U+gXI5YXKbWaEo7bwpy0+bNq418T7MD/3Pokvi5JT2ndLKh4ZJK4ZhGIPGHnYaQycbra1Xm2F0xibyJUFtzla8DWpIbRu1Ltp0SiWeQLuJovYGFZ+Owd+LRk4QLb8EWcarDmEbJZPETBn90pvo6eTLO9VtRUksTTbk0vEBUOG1GXm0EswLtaQSTzDRmFgiRCCsRiT0ySGCd2/CKzNvu9PYxksrQUoJkQxdQuqKyaDrsxa5EJVtU8khytEPU1JKzeywxyiHmTr/tdQyjcQya7uVwFz0DcMwho4Uz5jWDJvINwXz7DQ2HYFdkfeNkPlrWs2qLLV4hSRlRTmpWqKELsI+S7fiQVqpSiXUUkumxtsw/loIoJo1i+6rLtNoyaeQeFSCCZ14YtwuqUx9UsdMGNuCZqltg1WL9rREyZtS9dka4CpmtdLisVlYolSTQ2hvTaCeIMJLLL48lbszFgirsHCpHGKDZ2e7xJIldI0goagzUUstsTNEe4HqvrpYr6xOQokcgXSWEYeGXZEbhrEZCNb2rtQmcsMwNgR72GkYhjFsxB52Hjza7HAWIsmCAcR1+YnSoEWZGRYbzzyc1POAmnZeWq9tU9PK49p+pqM0lvtJXJVI4rYzGdGw2qi69H3WTAnd5+p17VL74G1Z69Nt43VvtW3U/DCrttEem7MkTJ5WEx+rr6ZcV0swMc8dfxY/J7WOPY3OfRCJk3XfXuvv8lxgNqS3LFmrxupO5IZhGH1iVivG4GG2tl5thtENsYediyJYebVJKax7Y84sv8T6cjJMTcrQX/yUyRi6EG4ktbxTaVS9TxctsaQ8Ux3RPjue1GF8kWMX/R0kJBbtpRlkkIq0Updb8rbK7FBLLUo+AUqyhztE77E5VrJIKuBVRQ5pya+pvTRTnp75fupl5W3aGMVMDZ23sVYS/T68ZJHywizveloPTd2+SYqpOVxPt6v5ke5ezENj6RO5YRjGwWBWK4ZhGMPGrFaMoSPM1jYW8yYyFonLLEYDdkV+cGgtVVc3bJraJmyrJ7Jye5VYIqC77KDLt42jvYMmjbxaJ8oMsaaZFw2TiaWnJnZ8flJJmR/WTBiV7g3UzRp19EPvbq/N/5QODtRd7bVZYU0jT5gS5ts2RywszA2rpoSFtl5y99faeMevImZJW9PVE1r5slmZv5s1tlpp/cpJXk3yHpKfTdST5FtJniD5aZLn9z9MwzCM+RAIZDLp9JoHko8neSPJO9zy2xPtLnFt7iB5San8TSTvJPlQ1312+e/+QwAXNtS/BMB57nUpgN/tunPjALHbcGPT8VfkXV7zcTmAD4rIeQA+6NYrkHw8gDcCeBaACwC8sTTh/7kr60yrtCIiHyV5bkOTiwC8S3L3t4+TfBzJM0Xk7qZ+KQI22T0l5ImoyVKr6WIiGUSl45Z/4Zo5XZOdVWLsXSWXprHoKI2qPFhzpiSWtv6biEoqzZ6cRbuq9BKiEZY+x7FKKunXglnfXvUYm0wG2/JnBvmjQ6KHNm9MLaGk6stMa27o5xZv3tcon6yoxLJ0RCB7uwexp4sAPM+9vwbARwD8kmrzYgA3isgDAEDyRuQXzO8RkY+7ss477OOrfhKAO0vrJ11ZDZKXkryZ5M333ndfD7s2DMPoinMI6vICjvq5yr0unWJHT/AXsm75HZE2nefNLvTxsDP2txG93BCRqwBcBQDPPP/8A/cHMAxjw+kum9wnIsdSlST/BsATI1W/3LH/zvNmF/qYyE8COLu0fhaAu3ro1zCMBOOJSSdTI/0FzRKRF6TqSH7Fy8skzwRwT6TZSRTyC5DPmx+ZdTx9TOTHAVxG8lrkwv2Dbfp4Gf0XlNSRg8YaibwX2jSf2brvqjmi188T+nHKLDKyT1HaVkoOTUV5y2LRBf3u9KOERB81F/5oo45aeUoHb2xTdQv3aP24HEpgXGvr21Rd5HW51sGBiL5ec5tHZV1r1k1u9W1aeL0vJNHPBUY1H/fEOUIWposu+uHQ7Mr9aA/y1nxei5SOHAdwCYAr3fLPIm1uAPAbpQecLwLwull32MX88D0A/h7Ad5E8SfJVJH+a5E+7JtcD+CKAEwB+H8DPzjoYwzCMhSECGU86vebkSgAvJHkHgBe6dZA8RvId+VDkAQC/BuAm97qi9ODzv5M8CeBRbs791bYddrFaeWVLvQB4dVs/hmEYy0REMNnbP4j93A/g+ZHymwH8VGn9agBXR9r9IoBfnGafq+PZGczWEiHadLsIbbKHljwgkb5apZVmyaBcqW8Z9S22JE3Q6uUpU6RUtDmiagaYStA7DTEpSNSbQrKofo762ItIglIrq7eNm/9p+aRiftiS9KGrKWHXNuV9abmk2qZFSNCnn/uCuyR48OPp47tOkUpGERufLtLj8p+FL+WitRZBH1fbK8nqTOSGYRgLxiZywzCMASMimFg8cmPITER6u+XeHQt2RsOykDAM4MCsVg6cpU/kSTlxmiiDLVp40EPVzmITGxOmf7oPrc9W20q0rk0zb0aPPd4qNb3m7WcTH2Pj3B03PwfQ+r92o9dmgdW66rZdM/P06VZfPSbdtlqvNfF5kgfrrD5Feb5clf/Paa4JFqnZT4WzWllHlj6RG4ZhHAQHZbWyDGwi3xAm0s3ywTDWmYldkR8QWhZpkliUSWDYJmGm5ond1mctpk81b0KpNm+SWEIftfrmfZXpOgl3uYvt6tmdOuVj424zraxLK/XvRkck1PtLRSwsxtDujanbtrXL66rrbVKK9lBtoqtU0uX7b/PsTFr0Rsr9/nxdV7PDaa4VvOQyjxQ1FWZ+aBiGMXBMIzcMwxg2ArNaWR2YzZ4YQTGeSCRI0WzsTwRbPfW1O55gp6fQdn2aCj6yLzi0xV777LOvU/sTHN7q53Nb9WcKo6x7vk/DIYLJrj3sXAheS/VauI/Wl8w0UyrT7vIp1229r3J5SJjbNk7Vp468B+STeeN+dZ8N0uCu+pV2NeGKNdudRrRt4ZF9ifapdc70d+DKSzq470tPTF1NCMuc2p9E61LbpEwKy2VdzQv7+Jj999zlAsP/1x+keV9SZ4+U6XHVImRItZ3/pddCafSFABO7IjcMwxguAtPIDcMwho0AYi76B4SSVJpus2q33CmvwhlMBRlkm7hpWZPEkvJQbJMbwnijNpDx+/aUWZinz7vUJikoZTIY6rUJn4pomLdJSCwJL8zQV4M3pqYt6cNckQsVXaR/LT+MEtEOvWlhppaxujbJpemc0WaHbe3q5RFv6Razx4OyPgTEHnYahmEMGrMjNwzDGDYigrFZrfSLkBCykCS8pJIwLYx7E8YllZSUomWQxlu61K35JN5H+ba7vl817qRnYsN4ksPTklD3Pvog6Z3aKrXUZZS9xG1vU0Crcn2MmKdmE17aiEksKanC799LKV2sSLRVSpuUouWSshenbqOZ55zwMkzw8Ex4cq5MYKxGTFoxDMMYNiatGIZhDBwBpEefilXCJnLDMDYCgVj0w4NCWrw2K239UmnjNc08tEOlXaWvhPellh27RPFrS/ir2xVjqI8rborYwAIuOLrIzElzvxZdO5bkONXHLFHyvJac0sq15hsSOEzhnz9qMQFt6kpHLGwzIdTa+TzEdO+u3XZppvtK/ZYODAFkumwug2HlJnLDMIxFIAKMd80hyDAMY7iImEa+KPwdr5dSmPicY8UTJZXUpBa1D206GBtHzWswPfTKPst3bPNKKl3klIPzhiuYRtqYRYpcpHzZJrF4+ox42JToIWUymJJSuuA/vz4CZ2qzw1nwH7XuY5kq9WRNJ/JOXznJC0l+geQJkpdH6n+C5L0kb3Wvn+p/qIZhGHPgzA+7vIZG6xU5yRGAtwN4IYCTAG4ieVxEPqeavldELlvAGA3DMOZGAEw2+GHnBQBOiMgXAYDktQAuAqAncsMwjNVFZKMfdj4JwJ2l9ZMAnhVp98MknwvgnwD8ZxG5UzcgeSmASwHg7LPPju/Nmx8mNOuqFl01/QuaeajPl7O41UO1bdMKK1H8WrTxrm7tqf4XzTzJcOe5K23VdifdBdvUMUyjOU9LyiSw6bjazAi9pt9l3G2fX1ukzMZte/jYli1YyBo7BHXRyGNfof40/hzAuSLybwH8DYBrYh2JyFUickxEjh0944zpRmoYhjEPbiLv8hoaXa7ITwIoXz6fBeCucgMRub+0+vsA3jz/0AzDMPpksz07bwJwHsmnAPgXABcD+I/lBiTPFJG73erLANzedQBabmAoj8sm5UQPqdyYuj4lqZT/eGO5JMvlbRaB5TvfaaMaroqk4mmL8tdEZ9O3GWSSaczqvLel/t32lNM6Sp8RAFNSSmwfKRPG4Lmpbqq1R2e5y9ZEJR3Go/dT9J3TNpUuTP1aY8/O1tNaRPYBXAbgBuQT9PtE5DaSV5B8mWv2cyRvI/kpAD8H4CcWNWDDMIxZEOR25F1e80Dy8SRvJHmHW357ot0lrs0dJC9xZY8i+ZckP+/m1Cu77LOTQ5CIXA/gelX2htL71wF4XZe+DMMwloIIJgdjtXI5gA+KyJXO7+ZyAL9UbkDy8QDeCOAY8v+YT5I8DuARAP9DRD5McgfAB0m+RET+qmmHC7zRNAxjUSxSIlpXRA7mihy5ebY3+LgGwA9F2rwYwI0i8oCIfBXAjQAuFJFviciH8/HKLoBbkD+XbGTpLvqakGy5R3HYn/PT/BenIiV2GVabxqcPUeuSZc1c97UMzdzTaxaYzH/AHczqOrrXR3czau6zD2YZV9f915Mz19/rNlobr2nVjLeL9uHbtoxLb1dpm1j3WjnDeFxkR/d5LuK/aooMQUdJ3lxav0pEruq47RP8M0MRuZvkd0TaxMy6n1RuQPJxAH4QwFvadrhyE7lhGMZCkKmutu8TkWOpSpJ/A+CJkapf7th/o1k3yS0A7wHwVu+M2YRN5IZhbAY9OgSJyAtSdSS/4i35SJ4J4J5Is5MAnldaPwvAR0rrVwG4Q0R+u8t4BjeRs8nOT+FvC6f57rSk0haZMDoEVdZH8tuis9n70kydtKJH/HGVpY89p31p/debEB5Egt8+EjnPI9s0SSmxeiBm5tdNUokx69C7SCopfDv9e2XP37fgwHJ2HgdwCYAr3fLPIm1uAPAbJYuWF8EZjJD8dQCPBdA5+KA9MjEMYzMQwXh30uk1J1cCeCHJO5AHG7wSAEgeI/mOfCjyAIBfQ+6ncxOAK0TkAZJnIZdnngbglq7RZAd3RW4YhjELIvPFEeq+H7kfwPMj5TejdJUtIlcDuFq1OYkZ7rsHN5GLSO+3XMZ0ZOBSZRnDmJVZLIyGwOAmcqDuit+VMP97s7/S/0Ghy1XbpMdQXW/8p5/j3BknNm7TixfxX1fW61Ou3F0n+JiVaVIPdqaKs8ibs16BzfODb9q2q+t9F2181fFfV0q/1eU1M8SeD1kw3fOyITHIidwwDGMW7IrcMAxjwEwE2F3ToFnLm8jFBXqf8h8y9j0s4rvxt3U6cmIX2iQAf7s/ze2yvtVOSQa+z0VceKRknlmIjV9/bn5/i3hANc2VWdtnnaKLGWKqD51Iuemc0clPvLyVSdUM0f9O/Kmk2zduoxMoq8+kyTu0TWIJUoo/noQ3aR+YtGIYhjFgBGLSimEYxpCxh50LQTARCbdd4VbNLfwH7qWXSbW6Uub/Zf3taNjG70m1i3lt+tvLoo9qeRi1Sk7hKcsCqVtxfTUwzdXBnr/Vbrld7/tJf4w+Iu/5z6v8WaXyU85yFXUQ9sJtElkX65WaRKGPPSE3xb6DWvA1Vn80vj50GZFNWrdBfRsg/nmnPEw92oz4IHwubSI3DMMYMCJmtWIYhjFoBGa1YhiGMWhMI18AhGB7sotHb28DALZlP6+QXCnbZi4CyigfokTM6ooEzV5vdF0kdPVafWk89aiH1W88ZYbYpMUu45wZiv+f/k6A+me7Kkk1unqrtiUubmKuCJltiUyS2zUklKiVV9um9tkUBbHNY3Mr879x/xyg/7PZpBXDMIwBk2vkyx7FYrCJ3DCMjcGuyPtGJuDewzhy5BAAYOJuwBhkj6p51tjdg5clj67SSTr/ZqmvWltldqiG3yWXZ+qWfNnn0kE+75nmWIcfUbF9/G3yS0pimUZlSPZR27ck2+v90XuLJvKDFvso17lcq2595IOf1TxM83b77sT0XR6Z7MYOY2YEB2PiuAzsitwwjI1AIGa1YhiGMWRyqxWbyA3DMIbLpj/sJHkhgLcAGAF4h4hcqeoPAXgXgGcCuB/AK0Tky42dTibg7sPY/ub9eR9jb36oQrlpsrR/uHABKUgX0WcKmV/BYw99LORz1MT20bbfGcbVeixd+myzDezh8zqQzzxB9JxJTXiTOc6vrlfDIWziuLndtLvH+l6Rt549JEcA3g7gJcgTgr6S5NNUs1cB+KqIPBXAbwF4c98DNQzDmJexdHsNjS6XARcAOCEiXxSRXQDXArhItbkIwDXu/XUAnk9LrGkYxgoxQe6i3+U1NLpIK08CcGdp/SSAZ6XaiMg+yQcBnA7gvnIjkpcCuNStPrLzxO/87CyDPmCOQh3HimLj7JchjHMIYwT6GeeT5x3Efdi94X/hn492bj4gukzksStr/ZfVpQ1E5CoAVwEAyZtF5FiH/S8VG2e/2Dj7YwhjBFZnnCJy4bLHsCi6SCsnAZxdWj8LwF2pNiS3ADwWwAN9DNAwDMNopstEfhOA80g+heQOgIsBHFdtjgO4xL1/OYAPybTJOA3DMIyZaJVWnOZ9GYAbkJsfXi0it5G8AsDNInIcwDsB/BHJE8ivxC/usO+r5hj3QWLj7BcbZ38MYYzAcMY5WGgXzoZhGMNmeV4IhmEYRi/YRG4YhjFwljKRk7yQ5BdIniB5+TLG0AbJq0neQ3Jlbd1Jnk3ywyRvJ3kbydcse0wxSB4m+Q8kP+XG+d+WPaYmSI5I/iPJv1j2WFKQ/DLJz5C8leTNyx5PCpKPI3kdyc+78/TZyx7TOnLgGrlz+f8nAC9EbrZ4E4BXisjnDnQgLZB8LoCHALxLRJ6+7PHEIHkmgDNF5BaS3wbgkwB+aAU/SwI4TUQeIrkN4GMAXiMiH1/y0KKQ/HkAxwA8RkReuuzxxCD5ZQDHRGSlHVdIXgPgb0XkHc7q7VEi8rVlj2vdWMYVeReX/6UjIh/FitvCi8jdInKLe/8NALcj97JdKSTnIbe67V4r+ZSd5FkAfgDAO5Y9lqFD8jEAnovcqg0ismuT+GJYxkQec/lfuclnaJA8F8AzAHxiuSOJ4+SKWwHcA+BGEVnJcQL4bQC/iNVPJiMA/g/JT7rQF6vIdwK4F8AfOKnqHSRPW/ag1pFlTOSd3PmN7pB8NID3A3itiHx92eOJISJjEfke5J7BF5BcObmK5EsB3CMin1z2WDrwHBE5H3lU0lc7KXDV2AJwPoDfFZFnAPgmgJV8JjZ0ljGRd3H5NzriNOf3A3i3iPzJssfThru1/giAVYx78RwAL3P687UAvo/kHy93SHFE5C63vAfAB5BLlqvGSQAnS3df1yGf2I2eWcZE3sXl3+iAe4j4TgC3i8hvLns8KUieQfJx7v0RAC8A8PnljqqOiLxORM4SkXORn5cfEpEfXfKwapA8zT3chpMqXgRg5ayrROT/AbiT5He5oucDWKkH8evCgad6S7n8H/Q42iD5HgDPA3CU5EkAbxSRdy53VDWeA+DHAHzG6c8A8HoRuX6JY4pxJoBrnMVSBuB9IrKypn0D4AkAPuBC/m8B+N8i8tfLHVKS/wTg3e6i7YsAfnLJ41lLzEXfMAxj4Jhnp2EYxsCxidwwDGPg2ERuGIYxcGwiNwzDGDg2kRuGYQwcm8gNwzAGjk3khmEYA+f/A+OGWe9+UmAEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = np.meshgrid(np.linspace(0, soln.shape[-2]*dx, soln.shape[-2]), np.linspace(0, soln.shape[-1]*dx, soln.shape[-1]), indexing = 'ij')\n",
    "#p_r = np.random.randint(0,soln.shape[0])\n",
    "z = soln[p_r,0,...]\n",
    "#z = rhs[p_r,...]\n",
    "print(z.shape)\n",
    "print(x.shape)\n",
    "z = mod(rhs)[p_r,0,...]\n",
    "#z = mod(rhs)[p_r,0,...]-soln[p_r,0,...]\n",
    "z_min, z_max = -np.abs(z).max(), np.abs(z).max()\n",
    "fig, ax = plt.subplots()\n",
    "c = ax.pcolormesh(x, y, z, cmap='RdBu', vmin=z_min, vmax=z_max)\n",
    "ax.set_title('result')\n",
    "ax.axis([x.min(), x.max(), y.min(), y.max()])\n",
    "fig.colorbar(c, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conv_laplacian_loss import conv_laplacian_loss\n",
    "cll = conv_laplacian_loss((ny,nx), dx)\n",
    "#cll(tf.expand_dims(rhs, axis = 1), tf.expand_dims(soln, axis = 1))\n",
    "cll(rhs,soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.compile(loss = lf, optimizer = tf.keras.optimizers.Adam(learning_rate = 5e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4314, shape=(10, 1), dtype=float64, numpy=\n",
       "array([[0.0125162 ],\n",
       "       [0.01514331],\n",
       "       [0.01004803],\n",
       "       [0.02955998],\n",
       "       [0.02036795],\n",
       "       [0.02593667],\n",
       "       [0.09950663],\n",
       "       [0.02465839],\n",
       "       [0.0333746 ],\n",
       "       [0.04933397]])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=72203, shape=(), dtype=float64, numpy=2.72116787741319>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = (tf.random.uniform((100,1,67,96), dtype = tf.float64), 0.05 * tf.ones((100,1), dtype = tf.float64))\n",
    "s = (tf.random.uniform((100,1,67,96), dtype = tf.float64), 0.05 * tf.ones((100,1), dtype = tf.float64))\n",
    "Lp_integral_norm_batch(r,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "---data---\n",
      "(1, 1, 100, 100)\n",
      "---index combinations---\n",
      "(20, 20, 4, 2)\n",
      "---interp_pts---\n",
      "(20, 20, 4, 1)\n",
      "---quadweights---\n",
      "tf.Tensor(\n",
      "[[7.75633119e-05 1.78788469e-04 2.75976477e-04 3.66709280e-04\n",
      "  4.48849465e-04 5.20469832e-04 5.79891154e-04 6.25720471e-04\n",
      "  6.56883512e-04 6.72649813e-04 6.72649813e-04 6.56883512e-04\n",
      "  6.25720471e-04 5.79891154e-04 5.20469832e-04 4.48849465e-04\n",
      "  3.66709280e-04 2.75976477e-04 1.78788469e-04 7.75633119e-05]\n",
      " [1.78788469e-04 4.12119025e-04 6.36143693e-04 8.45288694e-04\n",
      "  1.03462715e-03 1.19971675e-03 1.33668675e-03 1.44232630e-03\n",
      "  1.51415913e-03 1.55050148e-03 1.55050148e-03 1.51415913e-03\n",
      "  1.44232630e-03 1.33668675e-03 1.19971675e-03 1.03462715e-03\n",
      "  8.45288694e-04 6.36143693e-04 4.12119025e-04 1.78788469e-04]\n",
      " [2.75976477e-04 6.36143693e-04 9.81946411e-04 1.30478099e-03\n",
      "  1.59704235e-03 1.85187335e-03 2.06329918e-03 2.22636356e-03\n",
      "  2.33724415e-03 2.39334192e-03 2.39334192e-03 2.33724415e-03\n",
      "  2.22636356e-03 2.06329918e-03 1.85187335e-03 1.59704235e-03\n",
      "  1.30478099e-03 9.81946411e-04 6.36143693e-04 2.75976477e-04]\n",
      " [3.66709280e-04 8.45288694e-04 1.30478099e-03 1.73375392e-03\n",
      "  2.12210206e-03 2.46071387e-03 2.74165018e-03 2.95832524e-03\n",
      "  3.10566006e-03 3.18020109e-03 3.18020109e-03 3.10566006e-03\n",
      "  2.95832524e-03 2.74165018e-03 2.46071387e-03 2.12210206e-03\n",
      "  1.73375392e-03 1.30478099e-03 8.45288694e-04 3.66709280e-04]\n",
      " [4.48849465e-04 1.03462715e-03 1.59704235e-03 2.12210206e-03\n",
      "  2.59743733e-03 3.01189570e-03 3.35575967e-03 3.62096836e-03\n",
      "  3.80130510e-03 3.89254276e-03 3.89254276e-03 3.80130510e-03\n",
      "  3.62096836e-03 3.35575967e-03 3.01189570e-03 2.59743733e-03\n",
      "  2.12210206e-03 1.59704235e-03 1.03462715e-03 4.48849465e-04]\n",
      " [5.20469832e-04 1.19971675e-03 1.85187335e-03 2.46071387e-03\n",
      "  3.01189570e-03 3.49248685e-03 3.89121925e-03 4.19874578e-03\n",
      "  4.40785783e-03 4.51365377e-03 4.51365377e-03 4.40785783e-03\n",
      "  4.19874578e-03 3.89121925e-03 3.49248685e-03 3.01189570e-03\n",
      "  2.46071387e-03 1.85187335e-03 1.19971675e-03 5.20469832e-04]\n",
      " [5.79891154e-04 1.33668675e-03 2.06329918e-03 2.74165018e-03\n",
      "  3.35575967e-03 3.89121925e-03 4.33547437e-03 4.67811079e-03\n",
      "  4.91109687e-03 5.02897139e-03 5.02897139e-03 4.91109687e-03\n",
      "  4.67811079e-03 4.33547437e-03 3.89121925e-03 3.35575967e-03\n",
      "  2.74165018e-03 2.06329918e-03 1.33668675e-03 5.79891154e-04]\n",
      " [6.25720471e-04 1.44232630e-03 2.22636356e-03 2.95832524e-03\n",
      "  3.62096836e-03 4.19874578e-03 4.67811079e-03 5.04782607e-03\n",
      "  5.29922525e-03 5.42641550e-03 5.42641550e-03 5.29922525e-03\n",
      "  5.04782607e-03 4.67811079e-03 4.19874578e-03 3.62096836e-03\n",
      "  2.95832524e-03 2.22636356e-03 1.44232630e-03 6.25720471e-04]\n",
      " [6.56883512e-04 1.51415913e-03 2.33724415e-03 3.10566006e-03\n",
      "  3.80130510e-03 4.40785783e-03 4.91109687e-03 5.29922525e-03\n",
      "  5.56314497e-03 5.69666974e-03 5.69666974e-03 5.56314497e-03\n",
      "  5.29922525e-03 4.91109687e-03 4.40785783e-03 3.80130510e-03\n",
      "  3.10566006e-03 2.33724415e-03 1.51415913e-03 6.56883512e-04]\n",
      " [6.72649813e-04 1.55050148e-03 2.39334192e-03 3.18020109e-03\n",
      "  3.89254276e-03 4.51365377e-03 5.02897139e-03 5.42641550e-03\n",
      "  5.69666974e-03 5.83339932e-03 5.83339932e-03 5.69666974e-03\n",
      "  5.42641550e-03 5.02897139e-03 4.51365377e-03 3.89254276e-03\n",
      "  3.18020109e-03 2.39334192e-03 1.55050148e-03 6.72649813e-04]\n",
      " [6.72649813e-04 1.55050148e-03 2.39334192e-03 3.18020109e-03\n",
      "  3.89254276e-03 4.51365377e-03 5.02897139e-03 5.42641550e-03\n",
      "  5.69666974e-03 5.83339932e-03 5.83339932e-03 5.69666974e-03\n",
      "  5.42641550e-03 5.02897139e-03 4.51365377e-03 3.89254276e-03\n",
      "  3.18020109e-03 2.39334192e-03 1.55050148e-03 6.72649813e-04]\n",
      " [6.56883512e-04 1.51415913e-03 2.33724415e-03 3.10566006e-03\n",
      "  3.80130510e-03 4.40785783e-03 4.91109687e-03 5.29922525e-03\n",
      "  5.56314497e-03 5.69666974e-03 5.69666974e-03 5.56314497e-03\n",
      "  5.29922525e-03 4.91109687e-03 4.40785783e-03 3.80130510e-03\n",
      "  3.10566006e-03 2.33724415e-03 1.51415913e-03 6.56883512e-04]\n",
      " [6.25720471e-04 1.44232630e-03 2.22636356e-03 2.95832524e-03\n",
      "  3.62096836e-03 4.19874578e-03 4.67811079e-03 5.04782607e-03\n",
      "  5.29922525e-03 5.42641550e-03 5.42641550e-03 5.29922525e-03\n",
      "  5.04782607e-03 4.67811079e-03 4.19874578e-03 3.62096836e-03\n",
      "  2.95832524e-03 2.22636356e-03 1.44232630e-03 6.25720471e-04]\n",
      " [5.79891154e-04 1.33668675e-03 2.06329918e-03 2.74165018e-03\n",
      "  3.35575967e-03 3.89121925e-03 4.33547437e-03 4.67811079e-03\n",
      "  4.91109687e-03 5.02897139e-03 5.02897139e-03 4.91109687e-03\n",
      "  4.67811079e-03 4.33547437e-03 3.89121925e-03 3.35575967e-03\n",
      "  2.74165018e-03 2.06329918e-03 1.33668675e-03 5.79891154e-04]\n",
      " [5.20469832e-04 1.19971675e-03 1.85187335e-03 2.46071387e-03\n",
      "  3.01189570e-03 3.49248685e-03 3.89121925e-03 4.19874578e-03\n",
      "  4.40785783e-03 4.51365377e-03 4.51365377e-03 4.40785783e-03\n",
      "  4.19874578e-03 3.89121925e-03 3.49248685e-03 3.01189570e-03\n",
      "  2.46071387e-03 1.85187335e-03 1.19971675e-03 5.20469832e-04]\n",
      " [4.48849465e-04 1.03462715e-03 1.59704235e-03 2.12210206e-03\n",
      "  2.59743733e-03 3.01189570e-03 3.35575967e-03 3.62096836e-03\n",
      "  3.80130510e-03 3.89254276e-03 3.89254276e-03 3.80130510e-03\n",
      "  3.62096836e-03 3.35575967e-03 3.01189570e-03 2.59743733e-03\n",
      "  2.12210206e-03 1.59704235e-03 1.03462715e-03 4.48849465e-04]\n",
      " [3.66709280e-04 8.45288694e-04 1.30478099e-03 1.73375392e-03\n",
      "  2.12210206e-03 2.46071387e-03 2.74165018e-03 2.95832524e-03\n",
      "  3.10566006e-03 3.18020109e-03 3.18020109e-03 3.10566006e-03\n",
      "  2.95832524e-03 2.74165018e-03 2.46071387e-03 2.12210206e-03\n",
      "  1.73375392e-03 1.30478099e-03 8.45288694e-04 3.66709280e-04]\n",
      " [2.75976477e-04 6.36143693e-04 9.81946411e-04 1.30478099e-03\n",
      "  1.59704235e-03 1.85187335e-03 2.06329918e-03 2.22636356e-03\n",
      "  2.33724415e-03 2.39334192e-03 2.39334192e-03 2.33724415e-03\n",
      "  2.22636356e-03 2.06329918e-03 1.85187335e-03 1.59704235e-03\n",
      "  1.30478099e-03 9.81946411e-04 6.36143693e-04 2.75976477e-04]\n",
      " [1.78788469e-04 4.12119025e-04 6.36143693e-04 8.45288694e-04\n",
      "  1.03462715e-03 1.19971675e-03 1.33668675e-03 1.44232630e-03\n",
      "  1.51415913e-03 1.55050148e-03 1.55050148e-03 1.51415913e-03\n",
      "  1.44232630e-03 1.33668675e-03 1.19971675e-03 1.03462715e-03\n",
      "  8.45288694e-04 6.36143693e-04 4.12119025e-04 1.78788469e-04]\n",
      " [7.75633119e-05 1.78788469e-04 2.75976477e-04 3.66709280e-04\n",
      "  4.48849465e-04 5.20469832e-04 5.79891154e-04 6.25720471e-04\n",
      "  6.56883512e-04 6.72649813e-04 6.72649813e-04 6.56883512e-04\n",
      "  6.25720471e-04 5.79891154e-04 5.20469832e-04 4.48849465e-04\n",
      "  3.66709280e-04 2.75976477e-04 1.78788469e-04 7.75633119e-05]], shape=(20, 20), dtype=float64)\n",
      "---b---\n",
      "(20, 20, 4)\n",
      "---values_at_quad_pts---\n",
      "(20, 20, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=946104, shape=(), dtype=float64, numpy=0.38204612888195494>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(Homogeneous_Poisson_NN)\n",
    "mod = Homogeneous_Poisson_NN.Homogeneous_Poisson_NN_2(data_format = 'channels_first', Lp_norm_power=2)\n",
    "nx1 = 100\n",
    "nx2 = 100\n",
    "dx = 0.01\n",
    "Lx1 = 1.0\n",
    "Lx2 = 1.0\n",
    "batch_size = 1\n",
    "mod((tf.random.uniform((10,1,74,83), dtype = tf.keras.backend.floatx()), dx*tf.ones((batch_size,1), dtype = tf.keras.backend.floatx())))\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "x = np.array(np.meshgrid(np.linspace(0, Lx1, nx1),np.linspace(0, Lx2, nx2),indexing = 'xy'), dtype = np.float64).transpose((1,2,0))\n",
    "y = np.sin(x[:,:,0] - x[:,:,1])\n",
    "mod.integral_loss_2(y, tf.zeros((batch_size,1,nx1,nx2), dtype = tf.float64)) #ttf.ones((batch_size,1,nx1,nx2), dtype = tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01761401 0.04060143 0.06267205 0.08327674 0.10193012 0.11819453\n",
      " 0.13168864 0.14209611 0.14917299 0.15275339 0.15275339 0.14917299\n",
      " 0.14209611 0.13168864 0.11819453 0.10193012 0.08327674 0.06267205\n",
      " 0.04060143 0.01761401]\n",
      "[0.5 0.5]\n",
      "---data---\n",
      "(100, 100, 1, 1)\n",
      "---index combinations---\n",
      "(20, 20, 4, 2)\n",
      "---quadweights---\n",
      "tf.Tensor(\n",
      "[[7.75633119e-05 1.78788469e-04 2.75976477e-04 3.66709280e-04\n",
      "  4.48849465e-04 5.20469832e-04 5.79891154e-04 6.25720471e-04\n",
      "  6.56883512e-04 6.72649813e-04 6.72649813e-04 6.56883512e-04\n",
      "  6.25720471e-04 5.79891154e-04 5.20469832e-04 4.48849465e-04\n",
      "  3.66709280e-04 2.75976477e-04 1.78788469e-04 7.75633119e-05]\n",
      " [1.78788469e-04 4.12119025e-04 6.36143693e-04 8.45288694e-04\n",
      "  1.03462715e-03 1.19971675e-03 1.33668675e-03 1.44232630e-03\n",
      "  1.51415913e-03 1.55050148e-03 1.55050148e-03 1.51415913e-03\n",
      "  1.44232630e-03 1.33668675e-03 1.19971675e-03 1.03462715e-03\n",
      "  8.45288694e-04 6.36143693e-04 4.12119025e-04 1.78788469e-04]\n",
      " [2.75976477e-04 6.36143693e-04 9.81946411e-04 1.30478099e-03\n",
      "  1.59704235e-03 1.85187335e-03 2.06329918e-03 2.22636356e-03\n",
      "  2.33724415e-03 2.39334192e-03 2.39334192e-03 2.33724415e-03\n",
      "  2.22636356e-03 2.06329918e-03 1.85187335e-03 1.59704235e-03\n",
      "  1.30478099e-03 9.81946411e-04 6.36143693e-04 2.75976477e-04]\n",
      " [3.66709280e-04 8.45288694e-04 1.30478099e-03 1.73375392e-03\n",
      "  2.12210206e-03 2.46071387e-03 2.74165018e-03 2.95832524e-03\n",
      "  3.10566006e-03 3.18020109e-03 3.18020109e-03 3.10566006e-03\n",
      "  2.95832524e-03 2.74165018e-03 2.46071387e-03 2.12210206e-03\n",
      "  1.73375392e-03 1.30478099e-03 8.45288694e-04 3.66709280e-04]\n",
      " [4.48849465e-04 1.03462715e-03 1.59704235e-03 2.12210206e-03\n",
      "  2.59743733e-03 3.01189570e-03 3.35575967e-03 3.62096836e-03\n",
      "  3.80130510e-03 3.89254276e-03 3.89254276e-03 3.80130510e-03\n",
      "  3.62096836e-03 3.35575967e-03 3.01189570e-03 2.59743733e-03\n",
      "  2.12210206e-03 1.59704235e-03 1.03462715e-03 4.48849465e-04]\n",
      " [5.20469832e-04 1.19971675e-03 1.85187335e-03 2.46071387e-03\n",
      "  3.01189570e-03 3.49248685e-03 3.89121925e-03 4.19874578e-03\n",
      "  4.40785783e-03 4.51365377e-03 4.51365377e-03 4.40785783e-03\n",
      "  4.19874578e-03 3.89121925e-03 3.49248685e-03 3.01189570e-03\n",
      "  2.46071387e-03 1.85187335e-03 1.19971675e-03 5.20469832e-04]\n",
      " [5.79891154e-04 1.33668675e-03 2.06329918e-03 2.74165018e-03\n",
      "  3.35575967e-03 3.89121925e-03 4.33547437e-03 4.67811079e-03\n",
      "  4.91109687e-03 5.02897139e-03 5.02897139e-03 4.91109687e-03\n",
      "  4.67811079e-03 4.33547437e-03 3.89121925e-03 3.35575967e-03\n",
      "  2.74165018e-03 2.06329918e-03 1.33668675e-03 5.79891154e-04]\n",
      " [6.25720471e-04 1.44232630e-03 2.22636356e-03 2.95832524e-03\n",
      "  3.62096836e-03 4.19874578e-03 4.67811079e-03 5.04782607e-03\n",
      "  5.29922525e-03 5.42641550e-03 5.42641550e-03 5.29922525e-03\n",
      "  5.04782607e-03 4.67811079e-03 4.19874578e-03 3.62096836e-03\n",
      "  2.95832524e-03 2.22636356e-03 1.44232630e-03 6.25720471e-04]\n",
      " [6.56883512e-04 1.51415913e-03 2.33724415e-03 3.10566006e-03\n",
      "  3.80130510e-03 4.40785783e-03 4.91109687e-03 5.29922525e-03\n",
      "  5.56314497e-03 5.69666974e-03 5.69666974e-03 5.56314497e-03\n",
      "  5.29922525e-03 4.91109687e-03 4.40785783e-03 3.80130510e-03\n",
      "  3.10566006e-03 2.33724415e-03 1.51415913e-03 6.56883512e-04]\n",
      " [6.72649813e-04 1.55050148e-03 2.39334192e-03 3.18020109e-03\n",
      "  3.89254276e-03 4.51365377e-03 5.02897139e-03 5.42641550e-03\n",
      "  5.69666974e-03 5.83339932e-03 5.83339932e-03 5.69666974e-03\n",
      "  5.42641550e-03 5.02897139e-03 4.51365377e-03 3.89254276e-03\n",
      "  3.18020109e-03 2.39334192e-03 1.55050148e-03 6.72649813e-04]\n",
      " [6.72649813e-04 1.55050148e-03 2.39334192e-03 3.18020109e-03\n",
      "  3.89254276e-03 4.51365377e-03 5.02897139e-03 5.42641550e-03\n",
      "  5.69666974e-03 5.83339932e-03 5.83339932e-03 5.69666974e-03\n",
      "  5.42641550e-03 5.02897139e-03 4.51365377e-03 3.89254276e-03\n",
      "  3.18020109e-03 2.39334192e-03 1.55050148e-03 6.72649813e-04]\n",
      " [6.56883512e-04 1.51415913e-03 2.33724415e-03 3.10566006e-03\n",
      "  3.80130510e-03 4.40785783e-03 4.91109687e-03 5.29922525e-03\n",
      "  5.56314497e-03 5.69666974e-03 5.69666974e-03 5.56314497e-03\n",
      "  5.29922525e-03 4.91109687e-03 4.40785783e-03 3.80130510e-03\n",
      "  3.10566006e-03 2.33724415e-03 1.51415913e-03 6.56883512e-04]\n",
      " [6.25720471e-04 1.44232630e-03 2.22636356e-03 2.95832524e-03\n",
      "  3.62096836e-03 4.19874578e-03 4.67811079e-03 5.04782607e-03\n",
      "  5.29922525e-03 5.42641550e-03 5.42641550e-03 5.29922525e-03\n",
      "  5.04782607e-03 4.67811079e-03 4.19874578e-03 3.62096836e-03\n",
      "  2.95832524e-03 2.22636356e-03 1.44232630e-03 6.25720471e-04]\n",
      " [5.79891154e-04 1.33668675e-03 2.06329918e-03 2.74165018e-03\n",
      "  3.35575967e-03 3.89121925e-03 4.33547437e-03 4.67811079e-03\n",
      "  4.91109687e-03 5.02897139e-03 5.02897139e-03 4.91109687e-03\n",
      "  4.67811079e-03 4.33547437e-03 3.89121925e-03 3.35575967e-03\n",
      "  2.74165018e-03 2.06329918e-03 1.33668675e-03 5.79891154e-04]\n",
      " [5.20469832e-04 1.19971675e-03 1.85187335e-03 2.46071387e-03\n",
      "  3.01189570e-03 3.49248685e-03 3.89121925e-03 4.19874578e-03\n",
      "  4.40785783e-03 4.51365377e-03 4.51365377e-03 4.40785783e-03\n",
      "  4.19874578e-03 3.89121925e-03 3.49248685e-03 3.01189570e-03\n",
      "  2.46071387e-03 1.85187335e-03 1.19971675e-03 5.20469832e-04]\n",
      " [4.48849465e-04 1.03462715e-03 1.59704235e-03 2.12210206e-03\n",
      "  2.59743733e-03 3.01189570e-03 3.35575967e-03 3.62096836e-03\n",
      "  3.80130510e-03 3.89254276e-03 3.89254276e-03 3.80130510e-03\n",
      "  3.62096836e-03 3.35575967e-03 3.01189570e-03 2.59743733e-03\n",
      "  2.12210206e-03 1.59704235e-03 1.03462715e-03 4.48849465e-04]\n",
      " [3.66709280e-04 8.45288694e-04 1.30478099e-03 1.73375392e-03\n",
      "  2.12210206e-03 2.46071387e-03 2.74165018e-03 2.95832524e-03\n",
      "  3.10566006e-03 3.18020109e-03 3.18020109e-03 3.10566006e-03\n",
      "  2.95832524e-03 2.74165018e-03 2.46071387e-03 2.12210206e-03\n",
      "  1.73375392e-03 1.30478099e-03 8.45288694e-04 3.66709280e-04]\n",
      " [2.75976477e-04 6.36143693e-04 9.81946411e-04 1.30478099e-03\n",
      "  1.59704235e-03 1.85187335e-03 2.06329918e-03 2.22636356e-03\n",
      "  2.33724415e-03 2.39334192e-03 2.39334192e-03 2.33724415e-03\n",
      "  2.22636356e-03 2.06329918e-03 1.85187335e-03 1.59704235e-03\n",
      "  1.30478099e-03 9.81946411e-04 6.36143693e-04 2.75976477e-04]\n",
      " [1.78788469e-04 4.12119025e-04 6.36143693e-04 8.45288694e-04\n",
      "  1.03462715e-03 1.19971675e-03 1.33668675e-03 1.44232630e-03\n",
      "  1.51415913e-03 1.55050148e-03 1.55050148e-03 1.51415913e-03\n",
      "  1.44232630e-03 1.33668675e-03 1.19971675e-03 1.03462715e-03\n",
      "  8.45288694e-04 6.36143693e-04 4.12119025e-04 1.78788469e-04]\n",
      " [7.75633119e-05 1.78788469e-04 2.75976477e-04 3.66709280e-04\n",
      "  4.48849465e-04 5.20469832e-04 5.79891154e-04 6.25720471e-04\n",
      "  6.56883512e-04 6.72649813e-04 6.72649813e-04 6.56883512e-04\n",
      "  6.25720471e-04 5.79891154e-04 5.20469832e-04 4.48849465e-04\n",
      "  3.66709280e-04 2.75976477e-04 1.78788469e-04 7.75633119e-05]], shape=(20, 20), dtype=float64)\n",
      "---b---\n",
      "(20, 20, 4)\n",
      "---interp_pts---\n",
      "(20, 20, 4)\n",
      "---values_at_quad_pts---\n",
      "(20, 20, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=929183, shape=(), dtype=float64, numpy=0.3820461288819584>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf = Lp_integral_norm([nx1,nx2], [0,Lx1,0,Lx2], n_quadpts=20, p = 2.0)\n",
    "lf(y, tf.zeros((1,1,nx1,nx2), dtype = tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def Lp_integral_norm(image_size, domain, n_quadpts = 10, quadpts_randomization = 0, p=2, mse_component_weight = 0.0):\n",
    "    '''\n",
    "    This function generates a function that takes 2 function(s) evaluated on a 2D grid, the dimensions of which are stored in image_size, on a rectangular domain and evaluates the Lp norm of their difference using Gauss-Legendre quadrature\n",
    "    \n",
    "    image_size              :     tuple with 2 elements.\n",
    "    domain                  :     tuple with 4 elements containing (xmin,xmax,ymin,ymax)\n",
    "    n_quadpts               :     no of GL quadrature points\n",
    "    quadpts_randomization   :     if set to a nonzero value, the dataset inputted to the generated func. will be split into 2*quadpts_randomization+1 pieces and the integral for the ith piece will be computed with n_quadpts + i * quadpts_randomization GL pts (where i = [n_quadpts-quadpts_randomization, n_quadpts+quadpts_randomization])\n",
    "    p                       :     order of the Lp norm\n",
    "    \n",
    "    The shape of the inputs to the generated function must be (batch_size,channels,image_size[0],image_size[1])\n",
    "    \n",
    "    User inputs to the closure (generated function):\n",
    "    y_true                  :     labels\n",
    "    y_pred                  :     images\n",
    "    \n",
    "    '''\n",
    "    #match data types with keras\n",
    "    if tf.keras.backend.floatx() == 'float64':\n",
    "        dtype = tf.float64\n",
    "    elif tf.keras.backend.floatx() == 'float32':\n",
    "        dtype = tf.float32\n",
    "    else:\n",
    "        dtype = tf.float16\n",
    "    \n",
    "    #arrays to store values for different # of GL quad. pts. in accordance with quadpts_randomization. length of each: 2 * quadpts_randomization + 1\n",
    "    interpolation_weights = [] #array that stores weights b_ii such that the interpolated value at x,y is b_ii*f(X_i, Y_j) within a rectangle bounded by [X_1,X_2] x [Y_1, Y_2] (shapes: (n_quadpts, n_quadpts, 4, 2))\n",
    "    quadweights_list = [] #array that stores GL quad weights (shapes: (n_quadpts, n_quadpts))\n",
    "    index_combinations_list = [] #array of tensors, where each tensor stores the indices for the 4 points between which every GL quad pt lies (shapes: (no of quadpts, no of quadpts, 4, 2))\n",
    "    coords = np.array(np.meshgrid(np.linspace(domain[0], domain[1], image_size[0]),np.linspace(domain[2], domain[3], image_size[1]),indexing = 'xy'), dtype = np.float64).transpose((1,2,0)) #coordinates of each grid pt in the domain\n",
    "    image_coords = [coords[0,:,0], coords[:,1,1]] #x and y coordinates separately\n",
    "    c = np.array([np.array(0.5*(domain[1] - domain[0]),dtype=np.float64),np.array(0.5*(domain[3] - domain[2]),dtype=np.float64)]) #scaling coefficients - for handling domains other than [-1,1] x [-1,1]\n",
    "    d = np.array([np.array(0.5*(domain[1] + domain[0]),dtype=np.float64),np.array(0.5*(domain[3] + domain[2]),dtype=np.float64)])\n",
    "    for n in range(n_quadpts - quadpts_randomization, n_quadpts + quadpts_randomization+1): #loop over no of quadpts\n",
    "        quadrature_x, quadrature_w = tuple([np.polynomial.legendre.leggauss(n)[i].astype(np.float64) for i in range(2)]) #quadrature weights and points\n",
    "        print(quadrature_w)\n",
    "        quadpts = tf.constant(np.apply_along_axis(lambda x: x + d, 0, np.einsum('ijk,i->ijk',np.array(np.meshgrid(quadrature_x,quadrature_x,indexing = 'xy')),c)).transpose((1,2,0)),dtype = tf.float64)\n",
    "        #quadweights = tf.reduce_prod(c)*tf.tensordot(tf.squeeze(quadrature_w),tf.squeeze(quadrature_w),axes = 0)\n",
    "        quadweights = tf.reduce_prod(c) * tf.einsum('i,j->ij',tf.squeeze(quadrature_w),tf.squeeze(quadrature_w))\n",
    "        indices = [[],[]] #indices between each quadrature point lies - indices[0] is in x-dir and indices[1] is in the y-dir\n",
    "        quad_coords = [quadpts[0,:,0], quadpts[:,1,1]] #x and y coordinates of each quad pt respectively\n",
    "        #find the indices of coords between which every quad. pt. lies\n",
    "        for i in range(len(indices)):\n",
    "            j=0\n",
    "            #does not work if more than 2 quad pts fall within 1 cell - fix later\n",
    "            while len(indices[i]) < quadpts.shape[0] and j<image_coords[i].shape[0]:\n",
    "                try:\n",
    "                    if abs(float(quad_coords[i][len(indices[i])] - image_coords[i][j])) == float(min(abs(quad_coords[i][len(indices[i])] - image_coords[i][j-1]), abs(quad_coords[i][len(indices[i])] - image_coords[i][j]), abs(quad_coords[i][len(indices[i])] - image_coords[i][j+1]))):\n",
    "                        if quad_coords[i][len(indices[i])] - image_coords[i][j] < 0:\n",
    "                            indices[i].append((j-1,j))\n",
    "                        else:\n",
    "                            indices[i].append((j,j+1))\n",
    "                except:\n",
    "                    if abs(float(quad_coords[i][len(indices[i])] - image_coords[i][j])) == float(min(abs(quad_coords[i][len(indices[i])] - image_coords[i][j-1]), abs(quad_coords[i][len(indices[i])] - image_coords[i][j]))):\n",
    "                        indices[i].append((j-1,j))\n",
    "                j+=1\n",
    "        \n",
    "        index_combinations = np.zeros((quadpts.shape[0], quadpts.shape[1], 4 , 2), dtype = np.int32) #array storing the 4 index combinations on the original grid which surround each quad. pt.\n",
    "        corners = np.zeros((quadpts.shape[0], quadpts.shape[1], 2 , 2), dtype = np.int32) #array storing the lower left corner and the upper right corner of each box stored in index_combinations. effectively this will contain [[xmin,ymin],[xmax,ymax]] for the rectangle around each quad pt.\n",
    "        s=np.array(indices)\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                index_combinations[i,j,:,:] = np.array(list(itertools.product(np.array(s)[0,i,:],np.array(s)[1,j,:])))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                corners[i,j,:,:] = np.array([s[0,i,:],s[1,j,:]])\n",
    "        corners = corners.transpose((0,1,3,2))\n",
    "        corner_coords = tf.gather_nd(tf.transpose(coords,(1,0,2)),corners)\n",
    "        \n",
    "        #compute the coefficients [b_11,b_12,b_21,b_22]\n",
    "        #steps:\n",
    "        #1. compute transpose(invert(array([[1,xmin,ymin,xmin*ymin],[1,xmin,ymax,xmin*ymax],[1,xmax,ymin,xmax*ymin],[1,xmax,ymax,xmax*ymax]]))) for the rectangle around each quad pt.\n",
    "        #2. compute array([1,x_quadpt, y_quadpt, x_quadpt*y_quadpt]) for each quadpt\n",
    "        #3. multiply the result of 1 and 2 for each quad pt.\n",
    "        interpolation_matrix = np.ones((n,n,4,4))\n",
    "        interpolation_matrix[:,:,0:2,1] = np.einsum('ijk,ij->ijk',interpolation_matrix[:,:,0:2,1],corner_coords[:,:,0,0])\n",
    "        interpolation_matrix[:,:,2:,1] = np.einsum('ijk,ij->ijk',interpolation_matrix[:,:,2:,1],corner_coords[:,:,1,0])\n",
    "        interpolation_matrix[:,:,(0,2),2] = np.einsum('ijk,ij->ijk',interpolation_matrix[:,:,(0,2),2],corner_coords[:,:,0,1])\n",
    "        interpolation_matrix[:,:,(1,3),2] = np.einsum('ijk,ij->ijk',interpolation_matrix[:,:,(1,3),2], corner_coords[:,:,1,1])\n",
    "        interpolation_matrix[:,:,:,3] *= np.multiply(interpolation_matrix[:,:,:,1], interpolation_matrix[:,:,:,2])\n",
    "        interpolation_matrix = tf.transpose(tf.linalg.inv(interpolation_matrix), (0,1,3,2))\n",
    "        q = np.ones((n,n,4))\n",
    "        q[:,:,1] = tf.transpose(quadpts[:,:,0])\n",
    "        q[:,:,2] = tf.transpose(quadpts[:,:,1])\n",
    "        q[:,:,3] = np.multiply(q[:,:,1],q[:,:,2])\n",
    "        \n",
    "        b = tf.einsum('ijkl, ijl->ijk', tf.constant(interpolation_matrix), tf.constant(q))\n",
    "        \n",
    "        #store results for the closure\n",
    "        quadweights_list.append(tf.cast(quadweights,dtype))\n",
    "        index_combinations_list.append(index_combinations)\n",
    "        interpolation_weights.append(tf.cast(b, dtype))\n",
    "    print(c)\n",
    "    if int(tf.__version__[0]) < 2:\n",
    "        @tf.contrib.eager.defun\n",
    "        def Lp_integrate_batch(inp):\n",
    "            '''\n",
    "            Helper function to facilitate quad pt randomization\n",
    "\n",
    "            Given the bilinear interp. weights b, GL quad. weights w, Lp norm order p and the indices bounding each quad pt ind, computes the Lp norm for each channel/batch element\n",
    "            '''\n",
    "            #unpack values\n",
    "            data = tf.transpose(inp[0], (2,3,1,0))\n",
    "            b = inp[1]\n",
    "            w = inp[2]\n",
    "            ind = inp[3]\n",
    "            p = inp[4]\n",
    "\n",
    "            #get the points from the image to perform interpolation on\n",
    "            interp_pts = tf.squeeze(tf.gather_nd(data, ind))\n",
    "\n",
    "            #multiply image values with the weights b ti interpolate original image onto the GL quadrature points\n",
    "            if data.shape[-1] == 1: #needed to handle if batch dimension is 1\n",
    "                interp_pts = tf.expand_dims(interp_pts, axis = 3)\n",
    "            values_at_quad_pts = tf.einsum('ijkl, ijk->ijl', interp_pts, b)\n",
    "\n",
    "            #compute Lp norm\n",
    "            return tf.pow(tf.reduce_sum(tf.einsum('ij,ijk->ijk',w,tf.pow(values_at_quad_pts, p)), axis = (0,1)), 1/p)\n",
    "\n",
    "        @tf.contrib.eager.defun\n",
    "        def Lp_integrate(y_true,y_pred, b=interpolation_weights, w=quadweights_list, ind=index_combinations_list, p=p, mse_component_weight = mse_component_weight):\n",
    "            '''\n",
    "            Split the batch, pack with the appropriate parameters and obtain the integrals\n",
    "            '''\n",
    "            if mse_component_weight == 0.0:\n",
    "                return tf.reduce_mean(tf.concat(list(map(Lp_integrate_batch, zip(tf.split(y_true-y_pred, len(b)), itertools.cycle(b), itertools.cycle(w), itertools.cycle(ind), itertools.repeat(p)))), 0))\n",
    "            else:\n",
    "                return tf.reduce_mean(mse_component_weight * tf.keras.losses.mean_squared_error(y_true,y_pred)) + tf.reduce_mean(tf.concat(list(map(Lp_integrate_batch, zip(tf.split(y_true-y_pred, len(b)), itertools.cycle(b), itertools.cycle(w), itertools.cycle(ind), itertools.repeat(p)))), 0))\n",
    "    \n",
    "    else:\n",
    "        #@tf.function\n",
    "        def Lp_integrate_batch(inp):\n",
    "            '''\n",
    "            Helper function to facilitate quad pt randomization\n",
    "\n",
    "            Given the bilinear interp. weights b, GL quad. weights w, Lp norm order p and the indices bounding each quad pt ind, computes the Lp norm for each channel/batch element\n",
    "            '''\n",
    "            #unpack values\n",
    "            data = tf.transpose(inp[0], (2,3,1,0))\n",
    "            b = inp[1]\n",
    "            w = inp[2]\n",
    "            ind = inp[3]\n",
    "            p = inp[4]\n",
    "            \n",
    "            print('---data---')\n",
    "            print((data).shape)\n",
    "            print('---index combinations---')\n",
    "            print(ind.shape)\n",
    "            print('---quadweights---')\n",
    "            print(w)\n",
    "            print('---b---')\n",
    "            print(b.shape)\n",
    "            #get the points from the image to perform interpolation on\n",
    "            interp_pts = tf.squeeze(tf.gather_nd(data, ind))\n",
    "            \n",
    "            print('---interp_pts---')\n",
    "            print(interp_pts.shape)\n",
    "\n",
    "            if data.shape[-1] == 1: #needed to handle if batch dimension is 1\n",
    "                interp_pts = tf.expand_dims(interp_pts, axis = 3)\n",
    "            \n",
    "            if interp_pts.shape[0] == None:\n",
    "                interp_pts = tf.random.uniform(list(b.shape) + [100], dtype = tf.keras.backend.floatx())\n",
    "                \n",
    "            #multiply image values with the weights b ti interpolate original image onto the GL quadrature points\n",
    "            values_at_quad_pts = tf.einsum('ijkl, ijk->ijl', interp_pts, b)\n",
    "            print('---values_at_quad_pts---')\n",
    "            print(values_at_quad_pts.shape)\n",
    "    \n",
    "            #compute Lp norm\n",
    "            return tf.pow(tf.reduce_sum(tf.einsum('ij,ijk->ijk',w,tf.pow(values_at_quad_pts, p)), axis = (0,1)), 1/p)\n",
    "\n",
    "        #@tf.function\n",
    "        def Lp_integrate(y_true,y_pred, b=interpolation_weights, w=quadweights_list, ind=index_combinations_list, p=p, mse_component_weight = mse_component_weight):\n",
    "            '''\n",
    "            Split the batch, pack with the appropriate parameters and obtain the integrals\n",
    "            '''\n",
    "            if mse_component_weight == 0.0:\n",
    "                return tf.reduce_mean(tf.concat(list(map(Lp_integrate_batch, zip(tf.split(y_true-y_pred, len(b)), itertools.cycle(b), itertools.cycle(w), itertools.cycle(ind), itertools.repeat(p)))), 0))\n",
    "            else:\n",
    "                return tf.reduce_mean(mse_component_weight * tf.keras.losses.mean_squared_error(y_true,y_pred)) + tf.reduce_mean(tf.concat(list(map(Lp_integrate_batch, zip(tf.split(y_true-y_pred, len(b)), itertools.cycle(b), itertools.cycle(w), itertools.cycle(ind), itertools.repeat(p)))), 0))\n",
    "    return Lp_integrate\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
