{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Conv2DTranspose, AveragePooling2D, Add\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from Boundary import Boundary1D\n",
    "from collections.abc import Iterable\n",
    "import itertools, h5py\n",
    "from multiprocessing import Pool as ThreadPool\n",
    "opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.95)\n",
    "conf = tf.ConfigProto(gpu_options=opts)\n",
    "tfe.enable_eager_execution(config=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(tf.keras.layers.Layer):\n",
    "    def __init__(self, upsample_ratio = (2,2), output_dtype = tf.float32, data_format = 'channels_first', resize_method = tf.image.ResizeMethod.BICUBIC, **kwargs):\n",
    "        super(Upsample, self).__init__(**kwargs)\n",
    "        self.output_dtype = output_dtype\n",
    "        self.data_format = data_format\n",
    "        self.resize_method = resize_method\n",
    "        if not isinstance(upsample_ratio, Iterable):\n",
    "            self.upsample_ratio = (upsample_ratio, upsample_ratio)\n",
    "        else:\n",
    "            self.upsample_ratio = upsample_ratio\n",
    "            \n",
    "    def build(self, input_shape):\n",
    "        super(Upsample, self).build(input_shape)\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            return tf.TensorShape(list(input_shape)[0:2] + [self.upsample_ratio[0] * input_shape[-2], self.upsample_ratio[1] * input_shape[-1]])\n",
    "        else:\n",
    "            return tf.TensorShape([input_shape[0], self.upsample_ratio[0] * input_shape[-3], self.upsample_ratio[1] * input_shape[-2], input_shape[-1]])\n",
    "    \n",
    "#     def upsample(self, inp):\n",
    "#         dummy_coords_inp = (np.linspace(0,1,int(inp.shape[-2])), np.linspace(0,1,int(inp.shape[-1])))\n",
    "#         dummy_coords_out = (np.linspace(0,1,int(self.compute_output_shape(inp.shape)[-2])),np.linspace(0,1,int(self.compute_output_shape(inp.shape)[-1])))\n",
    "#         #pdb.set_trace()\n",
    "#         res = []\n",
    "#         for i in range(inp.shape[0]):\n",
    "#             spl = RectBivariateSpline(dummy_coords_inp[0], dummy_coords_inp[1], np.array(inp[i,...]))\n",
    "#             res.append(spl(dummy_coords_out[0], dummy_coords_out[1]))\n",
    "#         return tf.dtypes.cast(np.array(res), dtype=self.output_dtype)\n",
    "    \n",
    "#     @tf.contrib.eager.defun\n",
    "#     def upsample_wrap(self,inp):\n",
    "#         return tf.map_fn(self.upsample, inp)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "#         return self.upsample_wrap(inputs)\n",
    "        if self.data_format == 'channels_first':\n",
    "            return tf.transpose(tf.image.resize_images(tf.transpose(inputs, (0,2,3,1)), tf.multiply(self.upsample_ratio, inputs.shape[2:]), align_corners=True, method=self.resize_method), (0,3,1,2))\n",
    "        else:\n",
    "            return tf.image.resize_images(inputs, tf.multiply(self.upsample_ratio, inputs.shape[1:-1]), align_corners=True, method=self.resize_method)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_matrix(m,n):\n",
    "    '''\n",
    "    Generates the matrix A to express the Poisson equation in the form Ax=b for an m-by-n grid\n",
    "    \n",
    "    Them matrix returned shall be (m-2)*(n-2)-by-(m-2)*(n-2) in size\n",
    "    \n",
    "    CURRENTLY ONLY WORKS FOR SQUARE DOMAINS!!!!\n",
    "    '''\n",
    "    m = m-2\n",
    "    n = n-2\n",
    "    \n",
    "    D = np.zeros((m,m), dtype = np.float64)\n",
    "    i,j = np.indices(D.shape)\n",
    "    D[i==j] = 4.0\n",
    "    D[i==j-1] = -1.0\n",
    "    D[i==j+1] = -1.0\n",
    "    \n",
    "    S = -np.eye(D.shape[0], dtype = np.float64)\n",
    "    \n",
    "    P = np.zeros((m*n,m*n), dtype = np.float64)\n",
    "    ind = np.arange(0,m*(n+1), m)\n",
    "    \n",
    "    for i in range(len(ind)-1):\n",
    "        P[ind[i]:ind[i+1], ind[i]:ind[i+1]] = D\n",
    "        try:\n",
    "            P[ind[i+1]:ind[i+2], ind[i]:ind[i+1]] = S\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            P[ind[i-1]:ind[i], ind[i]:ind[i+1]] = S\n",
    "        except:\n",
    "            pass\n",
    "    return P\n",
    "\n",
    "def generate_random_RHS(n, n_controlpts = None, n_outputpts = None, s = 5, domain = [0,1,0,1]):\n",
    "    \n",
    "    '''\n",
    "    This function generates random smooth RHS 'functions' defined pointwise using bivariate splines. \n",
    "    n: no. of random RHSes to generate\n",
    "    n_controlpts: no. of control pts of the spline. Smaller values lead to 'smoother' results\n",
    "    n_outputpts: no. of gridpoints in each direction of the output \n",
    "    s: see parameter s in scipy.interpolate.RectBivariateSpline\n",
    "    domain: [x_min, x_max, y_min, y_max]\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if isinstance(n, Iterable):\n",
    "        n_controlpts = n[1]\n",
    "        n_outputpts = n[2]\n",
    "        try:\n",
    "            s = n[3]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            domain = n[4]\n",
    "        except:\n",
    "            pass\n",
    "        n = n[0]\n",
    "    \n",
    "    x = np.linspace(domain[0], domain[1], n_controlpts)\n",
    "    y = np.linspace(domain[2], domain[3], n_controlpts)\n",
    "    if n_controlpts != n_outputpts:\n",
    "        x_out = np.linspace(domain[0], domain[1], n_outputpts)\n",
    "        y_out = np.linspace(domain[2], domain[3], n_outputpts)\n",
    "    else:\n",
    "        x_out = x\n",
    "        y_out = y\n",
    "            \n",
    "    out = []\n",
    "    for i in range(n):\n",
    "        spl = RectBivariateSpline(x,y,2*np.random.rand(len(x), len(y))-1, s=s)\n",
    "        out.append(spl(x_out,y_out))\n",
    "    return np.array(out)\n",
    "    \n",
    "\n",
    "def poisson_RHS(F, boundaries = None, h = None):\n",
    "    '''\n",
    "    Generates the RHS vector b of a discretized Poisson problem in the form Ax=b.\n",
    "    h = grid spacing\n",
    "    boundaries = dict containing entries 'top', 'bottom', 'right' and 'left' which correspond to the Dirichlet BCs at these boundaries. Each entry must be a vector of length m or n, where m and n are defined as in te function poisson_matrix\n",
    "    F = an m by n matrix containing the RHS values of the Poisson equation\n",
    "    \n",
    "    (i.e. this function merely takes the BC information and the array from generate_random_RHS to provide the RHS for the matrix eq. form)\n",
    "    '''\n",
    "    \n",
    "    if isinstance(F, Iterable):\n",
    "        boundaries = F[1]\n",
    "        h = F[2]\n",
    "        F = F[0]\n",
    "    \n",
    "    F = -h**2 * F\n",
    "    F[...,1:-1,1] = F[...,1:-1,1] + np.array(boundaries['top'])[1:-1]\n",
    "    F[...,1:-1,-2] = F[...,1:-1,-2] + np.array(boundaries['bottom'])[1:-1]\n",
    "    F[...,1,1:-1] = F[...,1,1:-1] + np.array(boundaries['left'])[1:-1]\n",
    "    F[...,-2,1:-1] = F[...,-2,1:-1] + np.array(boundaries['right'])[1:-1]\n",
    "    \n",
    "    return F[...,1:-1,1:-1].reshape(list(F[...,1:-1,1:-1].shape[:-2]) + [np.prod(F[...,1:-1,1:-1].shape[-2:])])\n",
    " \n",
    "def generate_dataset(batch_size, n, h, boundaries, n_batches = 1, rhs_range = [-1,1]):\n",
    "    lhs = tf.constant(poisson_matrix(n,n), dtype=tf.float64)\n",
    "    lhs_chol = tf.linalg.cholesky(lhs)\n",
    "    \n",
    "    def chol(r):\n",
    "        return tf.linalg.cholesky_solve(lhs_chol, tf.transpose(tf.stack([r])))\n",
    "    \n",
    "    @tf.contrib.eager.defun\n",
    "    def chol_solve(rhs_arr):\n",
    "        return tf.map_fn(chol, rhs)\n",
    "    \n",
    "    #pdb.set_trace()\n",
    "    pool = ThreadPool(n_batches)\n",
    "    F = pool.map(generate_random_RHS, zip(itertools.repeat(batch_size, n_batches), itertools.repeat(10), itertools.repeat(n), itertools.repeat(5), itertools.repeat([0,n*h,0,n*h])))\n",
    "    rhs = tf.concat(pool.map(poisson_RHS, zip(F, itertools.repeat(boundaries), itertools.repeat(h))), axis=0)\n",
    "    \n",
    "    soln = np.zeros((n_batches * batch_size, n, n), dtype = np.float64)\n",
    "    soln[...,:,0] = boundaries['top']\n",
    "    soln[...,:,-1] = boundaries['bottom']\n",
    "    soln[...,0,:] = boundaries['left']\n",
    "    soln[...,-1,:] = boundaries['right']\n",
    "    soln[:,1:-1,1:-1] = tf.reshape(chol_solve(rhs), (n_batches * batch_size, n-2, n-2))\n",
    "    #soln = chol_solve(rhs)\n",
    "    \n",
    "    #return tf.reshape(soln, (n_batches, batch_size, lhs_chol.shape[0])), tf.reshape(F, (n_batches, batch_size, F.shape[-2], F.shape[-1]))\n",
    "    return tf.reshape(soln, (n_batches*batch_size, 1, soln.shape[-2], soln.shape[-1])), tf.reshape(tf.concat(F, axis = 0), (n_batches*batch_size, 1, F[0].shape[-2], F[0].shape[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lp_integrate_batch(inp):\n",
    "    #unpack values\n",
    "    data = tf.transpose(inp[0], (2,3,1,0))\n",
    "    b = inp[1]\n",
    "    w = inp[2]\n",
    "    ind = inp[3]\n",
    "    p = inp[4]\n",
    "    #print(w)\n",
    "    #get the points from the image to perform interpolation on\n",
    "    interp_pts = tf.squeeze(tf.gather_nd(data, ind))\n",
    "    #pdb.set_trace()\n",
    "    #multiply image values with the weights b ti interpolate original image onto the GL quadrature points\n",
    "    values_at_quad_pts = tf.einsum('ijkl, ijk->ijl', interp_pts, b)\n",
    "    #pdb.set_trace()\n",
    "    #compute Lp norm\n",
    "    return tf.pow(tf.reduce_sum(tf.einsum('ij,ijk->ijk',w,tf.pow(values_at_quad_pts, p)), axis = (0,1)), 1/p)\n",
    "    \n",
    "\n",
    "def Lp_integral_norm(image_size, domain, n_quadpts = 10, quadpts_randomization = 5, p=2):\n",
    "    interpolation_weights = []\n",
    "    quadweights_list = []\n",
    "    index_combinations_list = []\n",
    "    coords = np.array(np.meshgrid(np.linspace(domain[0], domain[1], image_size[0]),np.linspace(domain[2], domain[3], image_size[1]),indexing = 'xy'), dtype = np.float32).transpose((1,2,0))\n",
    "    c = np.array([np.array(0.5*(domain[1] - domain[0]),dtype=np.float64),np.array(0.5*(domain[3] - domain[2]),dtype=np.float32)]) #scaling coefficients - for handling domains other than [-1,1] x [-1,1]\n",
    "    d = np.array([np.array(0.5*(domain[1] + domain[0]),dtype=np.float64),np.array(0.5*(domain[3] + domain[2]),dtype=np.float32)])\n",
    "    for n in range(n_quadpts - quadpts_randomization, n_quadpts + quadpts_randomization+1):\n",
    "        quadrature_x, quadrature_w = tuple([np.polynomial.legendre.leggauss(n)[i].astype(np.float64) for i in range(2)]) #quadrature weights and points\n",
    "        quadpts = tf.constant(np.apply_along_axis(lambda x: x + d, 0, np.einsum('ijk,i->ijk',np.array(np.meshgrid(quadrature_x,quadrature_x,indexing = 'xy')),c)).transpose((1,2,0)),dtype = tf.float32)\n",
    "        quadweights = tf.reduce_prod(c)*tf.tensordot(quadrature_w,quadrature_w,axes = 0)\n",
    "        indices = [[],[]]\n",
    "        quad_coords = tf.stack([quadpts[0,:,0], quadpts[:,1,1]])\n",
    "        image_coords = tf.stack([coords[0,:,0], coords[:,1,1]])\n",
    "        for i in range(len(indices)):\n",
    "            j=0\n",
    "            while len(indices[i]) < quadpts.shape[0] and j<image_coords[i].shape[0]:\n",
    "                #pdb.set_trace()\n",
    "                #print(j)\n",
    "                if abs(float(quad_coords[i,len(indices[i])] - image_coords[i,j])) == float(min(abs(quad_coords[i,len(indices[i])] - image_coords[i,j-1]), abs(quad_coords[i,len(indices[i])] - image_coords[i,j]), abs(quad_coords[i,len(indices[i])] - image_coords[i,j+1]))):\n",
    "                    if quad_coords[i,len(indices[i])] - image_coords[i,j] < 0:\n",
    "                        indices[i].append((j-1,j))\n",
    "                    else:\n",
    "                        indices[i].append((j,j+1))\n",
    "                j+=1\n",
    "        \n",
    "\n",
    "        quadweights_list.append(quadweights)\n",
    "        index_combinations = np.zeros((quadpts.shape[0], quadpts.shape[1], 4 , 2), dtype = np.int32)\n",
    "        corners = np.zeros((quadpts.shape[0], quadpts.shape[1], 2 , 2), dtype = np.int32)\n",
    "        #corner_coords = np.zeros(corners.shape)\n",
    "        s=np.array(indices)\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                index_combinations[i,j,:,:] = np.array(list(itertools.product(np.array(s)[0,i,:],np.array(s)[1,j,:])))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                corners[i,j,:,:] = np.array([s[0,i,:],s[1,j,:]])\n",
    "        corners = corners.transpose((0,1,3,2))\n",
    "#         for i in range(n):\n",
    "#             for j in range(n):\n",
    "#                 for k in range(2):\n",
    "#                     corner_coords[i,j,k,:] = coords[corners[i,j,k,0],corners[i,j,k,1],:]\n",
    "        corner_coords = tf.transpose(tf.gather_nd(coords,corners),(1,0,2,3))\n",
    "        interpolation_matrix = np.ones((n,n,4,4))\n",
    "        interpolation_matrix[:,:,0:2,1] = np.einsum('ijk,ij->ijk',interpolation_matrix[:,:,0:2,1],corner_coords[:,:,0,0])\n",
    "        interpolation_matrix[:,:,2:,1] = np.einsum('ijk,ij->ijk',interpolation_matrix[:,:,2:,1],corner_coords[:,:,1,0])\n",
    "        interpolation_matrix[:,:,(0,2),2] = np.einsum('ijk,ij->ijk',interpolation_matrix[:,:,(0,2),2],corner_coords[:,:,0,1])\n",
    "        interpolation_matrix[:,:,(1,3),2] = np.einsum('ijk,ij->ijk',interpolation_matrix[:,:,(1,3),2], corner_coords[:,:,1,1])\n",
    "        interpolation_matrix[:,:,:,3] *= np.multiply(interpolation_matrix[:,:,:,1], interpolation_matrix[:,:,:,2])\n",
    "        #pdb.set_trace()\n",
    "        interpolation_matrix = tf.transpose(tf.linalg.inv(interpolation_matrix), (0,1,3,2))\n",
    "        q = np.ones((n,n,4))\n",
    "        q[:,:,1] = tf.transpose(quadpts[:,:,0])\n",
    "        q[:,:,2] = tf.transpose(quadpts[:,:,1])\n",
    "        q[:,:,3] = np.multiply(q[:,:,1],q[:,:,2])\n",
    "        \n",
    "        b = tf.einsum('ijkl, ijl->ijk', tf.constant(interpolation_matrix), tf.constant(q))\n",
    "        #pdb.set_trace()\n",
    "        index_combinations_list.append(index_combinations)\n",
    "        interpolation_weights.append(b)\n",
    "        #return interpolation_matrix[2,4,:,:], q[2,4,:], b[2,4,:]\n",
    "    \n",
    "    #pdb.set_trace()\n",
    "    \n",
    "#     def Lp_integrate_batch(inp):\n",
    "#         #unpack values\n",
    "#         data = tf.transpose(inp[0], (2,3,1,0))\n",
    "#         b = inp[1]\n",
    "#         w = inp[2]\n",
    "#         ind = inp[3]\n",
    "#         p = inp[4]\n",
    "        \n",
    "#         #get the points from the image to perform interpolation on\n",
    "#         interp_pts = tf.squeeze(tf.gather_nd(data, ind))\n",
    "#         #multiply image values with the weights b ti interpolate original image onto the GL quadrature points\n",
    "#         values_at_quad_pts = tf.einsum('ijkl, ijk->ijl', interp_pts, b)\n",
    "#         #compute Lp norm\n",
    "#         norm = tf.pow(tf.reduce_sum(tf.einsum('ij,ijk->ijk',w,tf.pow(values_at_quad_pts, p)), axis = (0,1)), 1/p)\n",
    "    \n",
    "    #@tfe.defun\n",
    "    def Lp_integrate(y_true,y_pred, b=interpolation_weights, w=quadweights_list, ind=index_combinations_list, p=p):\n",
    "        #pool = ThreadPool(len(b))\n",
    "        return tf.concat(list(map(Lp_integrate_batch, zip(tf.split(y_true-y_pred, len(b)), itertools.cycle(b), itertools.cycle(w), itertools.cycle(ind), itertools.repeat(p)))), 0)\n",
    "        \n",
    "    return Lp_integrate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest = 64\n",
    "h = 0.05\n",
    "boundary_top = Boundary1D('Dirichlet', [(0,ntest*h),(ntest*h,ntest*h)], orientation='clockwise', RHS_function=lambda t: t-t, boundary_rhs_is_parametric=True)\n",
    "boundary_right = Boundary1D('Dirichlet', [(ntest*h,ntest*h),(ntest*h,0)], orientation='clockwise', RHS_function=lambda t: t-t, boundary_rhs_is_parametric=True)\n",
    "boundary_bottom = Boundary1D('Dirichlet', [(ntest*h,0),(0,0)], orientation='clockwise', RHS_function=lambda t: t-t, boundary_rhs_is_parametric=True)\n",
    "boundary_left = Boundary1D('Dirichlet', [(0,0),(0,ntest*h)], orientation='clockwise', RHS_function=lambda t: t-t, boundary_rhs_is_parametric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "soln,F = generate_dataset(batch_size=2000, n = ntest, h = h, n_batches=20, boundaries={'top': boundary_top.RHS_evaluate(np.linspace(boundary_top.t.min(),boundary_top.t.max(),ntest)), 'right': boundary_right.RHS_evaluate(np.linspace(boundary_right.t.min(),boundary_right.t.max(),ntest)), 'bottom': boundary_bottom.RHS_evaluate(np.linspace(boundary_bottom.t.min(),boundary_bottom.t.max(),ntest)), 'left': boundary_left.RHS_evaluate(np.linspace(boundary_left.t.min(),boundary_left.t.max(),ntest))})\n",
    "t1 = time.time()\n",
    "print('Generation of training data took ' + str(t1-t0) + ' seconds')\n",
    "with h5py.File('dataset8.h5', 'w') as hf:\n",
    "    hf.create_dataset('soln', data=soln)\n",
    "    hf.create_dataset('F', data=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6,9):\n",
    "    with h5py.File('dataset' + str(i) + '.h5', 'r') as hf:\n",
    "        F = np.array(hf.get('F'), dtype = np.float64)\n",
    "        soln = np.array(hf.get('soln'), dtype = np.float64)\n",
    "        try:\n",
    "            train_data = train_data.concatenate(tf.data.Dataset.from_tensor_slices((F,soln)))\n",
    "        except:\n",
    "            train_data = tf.data.Dataset.from_tensor_slices((F,soln))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "soln_valid,F_valid = generate_dataset(batch_size=1000, n = ntest, h = h, n_batches=2, boundaries={'top': boundary_top.RHS_evaluate(np.linspace(boundary_top.t.min(),boundary_top.t.max(),ntest)), 'right': boundary_right.RHS_evaluate(np.linspace(boundary_right.t.min(),boundary_right.t.max(),ntest)), 'bottom': boundary_bottom.RHS_evaluate(np.linspace(boundary_bottom.t.min(),boundary_bottom.t.max(),ntest)), 'left': boundary_left.RHS_evaluate(np.linspace(boundary_left.t.min(),boundary_left.t.max(),ntest))})\n",
    "t1 = time.time()\n",
    "print('Generation of validation data took ' + str(t1-t0) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File('dataset' + str(4) + '.h5', 'r') as hf:\n",
    "#         F_valid = np.array(hf.get('F'), dtype = np.float64)\n",
    "#         soln_valid = np.array(hf.get('soln'), dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_size = 100000\n",
    "batch_size = 2000\n",
    "train_data = train_data.shuffle(shuffle_size).batch(batch_size)\n",
    "dataset_validation = tf.data.Dataset.from_tensor_slices((F_valid, soln_valid)).shuffle(shuffle_size).batch(100)\n",
    "#del F, soln#, F_valid, soln_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_0 = Input(shape=(1,ntest,ntest,))\n",
    "conv_1_0 = Conv2D(filters = 5, kernel_size = 3, activation=tf.nn.relu, data_format='channels_first', padding='same')(input_0)\n",
    "\n",
    "conv_2_0 = Conv2D(filters = 8, kernel_size = 3, activation=tf.nn.relu, data_format='channels_first', padding='same')(conv_1_0)\n",
    "pool_2_0 = AveragePooling2D(data_format = 'channels_first')(conv_2_0)\n",
    "pool_2_1 = AveragePooling2D(data_format = 'channels_first')(pool_2_0)\n",
    "\n",
    "conv_3_0 = Conv2D(filters = 8, kernel_size = 3, activation=tf.nn.relu, data_format = 'channels_first', padding='same')(conv_2_0)\n",
    "conv_3_1 = Conv2D(filters = 8, kernel_size = 3, activation=tf.nn.relu, data_format = 'channels_first', padding='same')(pool_2_0)\n",
    "conv_3_2 = Conv2D(filters = 8, kernel_size = 3, activation=tf.nn.relu, data_format = 'channels_first', padding='same')(pool_2_1)\n",
    "#transposeconv_3_1 = Conv2DTranspose(filters = 8, kernel_size = 3, strides = 2, activation = tf.nn.relu, data_format = 'channels_first', padding='same')(conv_3_1)\n",
    "#transposeconv_3_2 = Conv2DTranspose(filters = 8, kernel_size = 3, strides = 4, activation = tf.nn.relu, data_format = 'channels_first', padding='same')(conv_3_2)\n",
    "#upsample_3_1 = UpSampling2D(size=(2,2), data_format = 'channels_first', interpolation = 'bilinear')(conv_3_1)\n",
    "#upsample_3_2= UpSampling2D(size=(4,4), data_format = 'channels_first', interpolation = 'bilinear')(conv_3_2)\n",
    "upsample_3_1 = Upsample()(conv_3_1)\n",
    "upsample_3_2 = Upsample(4)(conv_3_2)\n",
    "#merge_3_0 = Add()([conv_3_0, transposeconv_3_1, transposeconv_3_2])\n",
    "merge_3_0 = Add()([conv_3_0, upsample_3_1, upsample_3_2])\n",
    "\n",
    "conv_4_0 = Conv2D(filters = 8, kernel_size = 1, activation = tf.nn.relu, data_format = 'channels_first', padding='same')(merge_3_0)\n",
    "\n",
    "conv_5_0 = Conv2D(filters = 1, kernel_size = 1, activation = 'linear', data_format = 'channels_first', padding='same')(conv_4_0)\n",
    "final_activation = tf.keras.layers.PReLU()(conv_5_0)\n",
    "a = Model(input_0, final_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.compile(optimizer = tf.train.AdamOptimizer(learning_rate=1e-3), loss = tf.losses.mean_squared_error, metrics = ['accuracy'])\n",
    "a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.fit(train_data, steps_per_epoch=8, epochs=7, validation_data=dataset_validation, validation_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.randint(0,F_valid.shape[0])\n",
    "y, x = np.meshgrid(np.linspace(0, ntest*h, ntest), np.linspace(0, ntest*h, ntest))\n",
    "z = a.predict(tf.expand_dims(F[p,...], axis=0))[0,0,...]\n",
    "#z = soln[p,0,...]\n",
    "#z = generate_random_RHS(10, n_controlpts=10, n_outputpts=64)[4,:,:]\n",
    "#z = a.predict(tf.expand_dims(F_valid[p,...], axis=0))[0,0,...] - soln_valid[p,0,...]\n",
    "z_min, z_max = -np.abs(z).max(), np.abs(z).max()\n",
    "fig, ax = plt.subplots()\n",
    "c = ax.pcolormesh(x, y, z, cmap='RdBu', vmin=z_min, vmax=z_max)\n",
    "ax.set_title('pcolormesh')\n",
    "ax.axis([x.min(), x.max(), y.min(), y.max()])\n",
    "fig.colorbar(c, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soln_valid,F_valid = generate_dataset(batch_size=50, n = ntest, h = h, n_batches=1, boundaries={'top': boundary_top.RHS_evaluate(np.linspace(boundary_top.t.min(),boundary_top.t.max(),ntest)), 'right': boundary_right.RHS_evaluate(np.linspace(boundary_right.t.min(),boundary_right.t.max(),ntest)), 'bottom': boundary_bottom.RHS_evaluate(np.linspace(boundary_bottom.t.min(),boundary_bottom.t.max(),ntest)), 'left': boundary_left.RHS_evaluate(np.linspace(boundary_left.t.min(),boundary_left.t.max(),ntest))})\n",
    "#p = np.random.randint(0,F_valid.shape[0])\n",
    "y, x = np.meshgrid(np.linspace(0, ntest*h, ntest), np.linspace(0, ntest*h, ntest))\n",
    "z = F[p,0,...]\n",
    "#z = soln[p,0,...]\n",
    "z_min, z_max = -np.abs(z).max(), np.abs(z).max()\n",
    "fig, ax = plt.subplots()\n",
    "c = ax.pcolormesh(x, y, z, cmap='RdBu', vmin=z_min, vmax=z_max)\n",
    "ax.set_title('pcolormesh')\n",
    "ax.axis([x.min(), x.max(), y.min(), y.max()])\n",
    "fig.colorbar(c, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(1,ntest-2)\n",
    "j = np.random.randint(1,ntest-2)\n",
    "p = np.random.randint(0,soln_valid.shape[0]-1)\n",
    "print((-4 * soln_valid[p,0,i,j] + soln_valid[p,0,i,j-1] + soln_valid[p,0,i-1,j] + soln_valid[p,0,i+1,j] + soln_valid[p,0,i,j+1])/(h**2))\n",
    "example_soln = a.predict(tf.expand_dims(F_valid[p,...], axis=0))\n",
    "print((-4 * example_soln[0,0,i,j] + example_soln[0,0,i,j-1] + example_soln[0,0,i-1,j] + example_soln[0,0,i+1,j] + example_soln[0,0,i,j+1])/(h**2))\n",
    "print(F_valid[p,0,i,j])\n",
    "print(soln_valid[p,0,i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = np.meshgrid(np.linspace(0,1,20),np.linspace(0,1,20))\n",
    "Z_m = np.array([[np.sin(np.pi*(X+Y)), np.cos(np.pi * (X+Y))] , [np.exp(-X**2 * Y**2), np.tan(np.multiply(X,Y))]])\n",
    "#Z_m = tf.expand_dims(Z, axis = 0)\n",
    "ur = 3\n",
    "b = BilinearUpsample(ur)(input_0)\n",
    "model1 = Model(input_0, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0, Y0 = np.meshgrid(np.linspace(0,1,X.shape[0]*ur),np.linspace(0,1,X.shape[0]*ur))\n",
    "fig, ax = plt.subplots()\n",
    "c = ax.pcolormesh(X0, Y0, model1(Z_m)[0,0,...], cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "c = ax.pcolormesh(X, Y, Z_m[0,0,...], cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(a.predict(F_valid) - soln_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit a.predict(tf.expand_dims(F_valid[0,...], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit a.predict(F_valid[0:1000,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhs = poisson_matrix(64,64)\n",
    "lhs_chol = tf.to_float(tf.linalg.cholesky(lhs))\n",
    "print(lhs_chol.shape)\n",
    "rhs = tf.constant(np.random.rand((64-2)**2,1000ur), dtype=tf.float32)\n",
    "print(rhs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit tf.linalg.cholesky_solve(lhs_chol,rhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_quadpts = 12\n",
    "domain = [0,3.2,0,3.2]\n",
    "quadrature_x, quadrature_w = tuple([np.polynomial.legendre.leggauss(n_quadpts)[i].astype(np.float32) for i in range(2)]) #quadrature weights and points\n",
    "c = np.array([np.array(0.5*(domain[1] - domain[0]),dtype=np.float32),np.array(0.5*(domain[3] - domain[2]),dtype=np.float32)]) #scaling coefficients - for handling domains other than [-1,1] x [-1,1]\n",
    "d = np.array([np.array(0.5*(domain[1] + domain[0]),dtype=np.float32),np.array(0.5*(domain[3] + domain[2]),dtype=np.float32)])\n",
    "quadpts = tf.constant(np.apply_along_axis(lambda x: x + d, 0, np.einsum('ijk,i->ijk',np.array(np.meshgrid(quadrature_x,quadrature_x,indexing = 'xy')),c)).transpose((1,2,0)),dtype = tf.float32)\n",
    "quadweights = tf.reduce_prod(c)*tf.tensordot(quadrature_w,quadrature_w,axes = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(quadpts[0,:,0])\n",
    "x_image = np.linspace(domain[0], domain[1], ntest)\n",
    "print(x_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "indices = []\n",
    "j=0\n",
    "while len(indices) < quadpts.shape[0] and j<x_image.shape[0]:\n",
    "    #pdb.set_trace()\n",
    "    #print(j)\n",
    "    if abs(float(quadpts[0,len(indices),0] - x_image[j])) == float(min(abs(quadpts[0,len(indices),0] - x_image[j-1]), abs(quadpts[0,len(indices),0] - x_image[j]), abs(quadpts[0,len(indices),0] - x_image[j+1]))):\n",
    "        if quadpts[0,len(indices),0] - x_image[j] < 0:\n",
    "            indices.append((j-1,j))\n",
    "        else:\n",
    "            indices.append((j,j+1))\n",
    "\n",
    "    j+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.stack([np.array([3,4,5]), np.array([0,1,2])]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-85-bc7d2a1c88d0>(78)Lp_integral_norm()\n",
      "-> index_combinations_list.append(index_combinations)\n",
      "[1.         0.33787328 1.83603108 0.62034584]\n",
      "tf.Tensor([0.11782257 0.5961614  0.04719874 0.23881729], shape=(4,), dtype=float64)\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-cc7ee10d7484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLp_integral_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquadpts_randomization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# s = np.array(L2_integral_norm((64,64), [0,3.2,0,3.2], quadpts_randomization=1)[2][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(s[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-bc7d2a1c88d0>\u001b[0m in \u001b[0;36mLp_integral_norm\u001b[0;34m(image_size, domain, n_quadpts, quadpts_randomization, p)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ijkl, ijl->ijk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpolation_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mindex_combinations_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_combinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0minterpolation_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m#return interpolation_matrix[2,4,:,:], q[2,4,:], b[2,4,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-bc7d2a1c88d0>\u001b[0m in \u001b[0;36mLp_integral_norm\u001b[0;34m(image_size, domain, n_quadpts, quadpts_randomization, p)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ijkl, ijl->ijk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpolation_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mindex_combinations_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_combinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0minterpolation_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m#return interpolation_matrix[2,4,:,:], q[2,4,:], b[2,4,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test1/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test1/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "print(Lp_integral_norm((64,64), [0,1,0,2], quadpts_randomization=1))\n",
    "# s = np.array(L2_integral_norm((64,64), [0,3.2,0,3.2], quadpts_randomization=1)[2][0])\n",
    "# print(s)\n",
    "# print(s[0])\n",
    "# print(len(s[0]))\n",
    "# print(s[1][2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(itertools.product(np.array(s)[0,5,:],np.array(s)[1,3,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_combinations = np.zeros((s.shape[1], s.shape[1], 4 , 2), dtype = np.int32)\n",
    "for i in range(9):\n",
    "    for j in range(9):\n",
    "        index_combinations[i,j,:,:] = np.array(list(itertools.product(np.array(s)[0,i,:],np.array(s)[1,j,:])))\n",
    "#print(index_combinations)\n",
    "coords = np.array(np.meshgrid(x_image,x_image)).transpose(1,2,0)\n",
    "print(index_combinations[0,0,0,:])\n",
    "coords[index_combinations[0,0,1,0],index_combinations[0,0,1,1],:]\n",
    "testdata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = tf.constant(np.ones((4500,1,64,64)))\n",
    "c = np.arange(4500, dtype = np.float64)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_ret():\n",
    "    @tfe.defun\n",
    "    def testfun(inp):\n",
    "        #print(inp[1])\n",
    "        return 0*tf.reduce_sum(inp[0]) + tf.reduce_sum(inp[1])\n",
    "    @tfe.defun\n",
    "    def testfun_wrap(tensors,coeffs):\n",
    "        return tf.map_fn(testfun, (tf.split(tensors, 3), tf.split(c,3)),dtype = tf.float64)\n",
    "    return testfun_wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = wrapper_ret()\n",
    "#testfun_wrap(testdata,c)\n",
    "import time\n",
    "t0 = time.time()\n",
    "f(testdata,c)\n",
    "t1 = time.time()\n",
    "print(t1-t0)\n",
    "#tf.split(testdata, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array([[0,2],[1,3]], dtype = np.int32)\n",
    "a = tf.random.uniform((6,4,5,5),dtype=tf.float32)\n",
    "print(tf.gather_nd(a[0,0],q))\n",
    "# print(a[0,2,...])\n",
    "# print(a[1,3,...])\n",
    "print(a[0,0,0,2])\n",
    "print(a[0,0,1,3])\n",
    "print(q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = tf.tile(tf.constant(np.array([[1,2,3], [2,3,4]]), dtype=tf.float32),[2,1])\n",
    "print(q.shape)\n",
    "s = tf.ones((12,3), dtype=tf.float32)\n",
    "def f(x):\n",
    "    return tf.reduce_sum(tf.einsum('ij,j->i', x[0], x[1]))\n",
    "tf.map_fn(f, (tf.stack(tf.split(s,4)), q), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = np.meshgrid(np.linspace(0,1,110), np.linspace(0,2,73), indexing = 'xy')\n",
    "f = tf.expand_dims(np.array([X + Y,X*Y, X-Y, X**2 + Y**2, X**2 - Y**2, X-2*Y]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shapes of all inputs must match: values[0].shape = [110] != values[1].shape = [73] [Op:Pack] name: stack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-30b1d561bf15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLp_integral_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m110\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m73\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_quadpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquadpts_randomization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-102-290e5bb4c975>\u001b[0m in \u001b[0;36mLp_integral_norm\u001b[0;34m(image_size, domain, n_quadpts, quadpts_randomization, p)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mquad_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquadpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquadpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mimage_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test1/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m    872\u001b[0m                                                       expanded_num_dims))\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test1/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   4897\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4898\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4899\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test1/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [110] != values[1].shape = [73] [Op:Pack] name: stack"
     ]
    }
   ],
   "source": [
    "g = Lp_integral_norm((110,73), [0,1,0,2], n_quadpts=10, quadpts_randomization=1, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1083873, shape=(6,), dtype=float64, numpy=\n",
       "array([2.30940114, 0.9428091 , 1.15470052, 2.92883149, 2.24106334,\n",
       "       2.70801279])>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(f, np.zeros((6,1,110,73), dtype = np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.47 ms ± 155 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit g(tf.random.uniform((3000,1,64,64), dtype=tf.float64), tf.random.uniform((3000,1,64,64), dtype = tf.float64))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6",
   "language": "python",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
